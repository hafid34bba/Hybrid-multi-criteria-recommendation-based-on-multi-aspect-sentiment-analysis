{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PFE_part1+agg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYvnzF_meGNd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Dense, Input, Flatten, concatenate,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/trip_advisor_data.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "dgu3uU7UffMH",
        "outputId": "7b1b1300-3cd8-4cef-a8d9-be0188fd1d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   overall  cleanliness location  rooms  service  value  \\\n",
              "0      4.0          5.0      5.0    5.0      4.0    3.0   \n",
              "1      4.0          5.0      5.0    5.0      4.0    5.0   \n",
              "2      5.0          5.0      4.0    5.0      5.0    3.0   \n",
              "3      4.0          4.0      3.0    4.0      4.0    4.0   \n",
              "4      4.0          4.0      4.0    5.0      4.0    4.0   \n",
              "\n",
              "                                             title  \\\n",
              "0  “Its the best of the Andaz Brand in the US....”   \n",
              "1                          “Stunningly Wonderful!”   \n",
              "2                              “Unexpectedly good”   \n",
              "3           “Pleasant enough, but a bit overrated”   \n",
              "4                                   “nice suprise”   \n",
              "\n",
              "                                                text             username  \\\n",
              "0  I have stayed at each of the US Andaz properti...            JamesE339   \n",
              "1  Other hotels in NYC that are space challenged ...             romadaro   \n",
              "2  Campus hotels are a little unpredictable, but ...            Grotshops   \n",
              "3  For our most recent ever-so-brief New York vis...  pillowsofwanderlust   \n",
              "4  Booked this hotel thinking it was another Hilt...     beatricepugzilla   \n",
              "\n",
              "   num_cities  num_helpful_votes  num_reviews  num_type_reviews         id  \\\n",
              "0        34.0                  0        104.0              49.0  147612823   \n",
              "1        70.0                  5        103.0              85.0  147531970   \n",
              "2        35.0                  0         96.0              51.0  140624089   \n",
              "3        20.0                  2         57.0              49.0  145940048   \n",
              "4        28.0                  2         41.0              36.0  127060765   \n",
              "\n",
              "      date_stayed  offering_id                date  via_mobile  \\\n",
              "0   December 2012      1762573   December 17, 2012       False   \n",
              "1   December 2012      1762573   December 16, 2012       False   \n",
              "2  September 2012       108038  September 18, 2012       False   \n",
              "3   November 2012      1776857   November 22, 2012       False   \n",
              "4      March 2012       108038       April 1, 2012       False   \n",
              "\n",
              "                            user_id  \n",
              "0  BA524A238B1171206691A6CC3F28F266  \n",
              "1  C81AB7D49D98FA410EA191E15F427BEC  \n",
              "2  4C8EFD12CA2F03E9D85709814BB16501  \n",
              "3  3F88F8D4F220EFE6418ED0B22AAF03E6  \n",
              "4  A90E45A9CAD3E818327172C16C27BFB1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80ba6add-7df4-4690-804c-64fdd00f8fc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>cleanliness</th>\n",
              "      <th>location</th>\n",
              "      <th>rooms</th>\n",
              "      <th>service</th>\n",
              "      <th>value</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>username</th>\n",
              "      <th>num_cities</th>\n",
              "      <th>num_helpful_votes</th>\n",
              "      <th>num_reviews</th>\n",
              "      <th>num_type_reviews</th>\n",
              "      <th>id</th>\n",
              "      <th>date_stayed</th>\n",
              "      <th>offering_id</th>\n",
              "      <th>date</th>\n",
              "      <th>via_mobile</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>“Its the best of the Andaz Brand in the US....”</td>\n",
              "      <td>I have stayed at each of the US Andaz properti...</td>\n",
              "      <td>JamesE339</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>147612823</td>\n",
              "      <td>December 2012</td>\n",
              "      <td>1762573</td>\n",
              "      <td>December 17, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>BA524A238B1171206691A6CC3F28F266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>“Stunningly Wonderful!”</td>\n",
              "      <td>Other hotels in NYC that are space challenged ...</td>\n",
              "      <td>romadaro</td>\n",
              "      <td>70.0</td>\n",
              "      <td>5</td>\n",
              "      <td>103.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>147531970</td>\n",
              "      <td>December 2012</td>\n",
              "      <td>1762573</td>\n",
              "      <td>December 16, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>C81AB7D49D98FA410EA191E15F427BEC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>“Unexpectedly good”</td>\n",
              "      <td>Campus hotels are a little unpredictable, but ...</td>\n",
              "      <td>Grotshops</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>140624089</td>\n",
              "      <td>September 2012</td>\n",
              "      <td>108038</td>\n",
              "      <td>September 18, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>4C8EFD12CA2F03E9D85709814BB16501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>“Pleasant enough, but a bit overrated”</td>\n",
              "      <td>For our most recent ever-so-brief New York vis...</td>\n",
              "      <td>pillowsofwanderlust</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>57.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>145940048</td>\n",
              "      <td>November 2012</td>\n",
              "      <td>1776857</td>\n",
              "      <td>November 22, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>3F88F8D4F220EFE6418ED0B22AAF03E6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>“nice suprise”</td>\n",
              "      <td>Booked this hotel thinking it was another Hilt...</td>\n",
              "      <td>beatricepugzilla</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2</td>\n",
              "      <td>41.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>127060765</td>\n",
              "      <td>March 2012</td>\n",
              "      <td>108038</td>\n",
              "      <td>April 1, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>A90E45A9CAD3E818327172C16C27BFB1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80ba6add-7df4-4690-804c-64fdd00f8fc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80ba6add-7df4-4690-804c-64fdd00f8fc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80ba6add-7df4-4690-804c-64fdd00f8fc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "ONrAcBlN4wvx",
        "outputId": "9072e226-3e2b-4feb-cef1-e394154ea8bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            overall   cleanliness         rooms       service         value  \\\n",
              "count  10050.000000  10050.000000  10050.000000  10050.000000  10050.000000   \n",
              "mean       4.038706      4.294726      4.012736      4.165473      3.949751   \n",
              "std        1.104904      1.010100      1.101676      1.128248      1.145136   \n",
              "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "25%        4.000000      4.000000      3.000000      4.000000      3.000000   \n",
              "50%        4.000000      5.000000      4.000000      5.000000      4.000000   \n",
              "75%        5.000000      5.000000      5.000000      5.000000      5.000000   \n",
              "max        5.000000      5.000000      5.000000      5.000000      5.000000   \n",
              "\n",
              "        num_cities  num_helpful_votes  num_reviews  num_type_reviews  \\\n",
              "count  7682.000000       10050.000000  9993.000000       6444.000000   \n",
              "mean     12.655038           1.019801    17.448714         14.027933   \n",
              "std      14.029587           2.313198    26.746115         16.229405   \n",
              "min       2.000000           0.000000     1.000000          3.000000   \n",
              "25%       4.000000           0.000000     2.000000          5.000000   \n",
              "50%       8.000000           0.000000     8.000000          9.000000   \n",
              "75%      16.000000           1.000000    22.000000         17.000000   \n",
              "max     202.000000          63.000000   472.000000        259.000000   \n",
              "\n",
              "                 id   offering_id  \n",
              "count  1.005000e+04  1.005000e+04  \n",
              "mean   9.109240e+07  3.099200e+05  \n",
              "std    4.854196e+07  4.394021e+05  \n",
              "min    6.978530e+05  7.257200e+04  \n",
              "25%    4.819406e+07  8.759000e+04  \n",
              "50%    1.184954e+08  1.095195e+05  \n",
              "75%    1.318665e+08  2.496960e+05  \n",
              "max    1.477548e+08  3.236579e+06  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af9d2c4f-6791-402f-8d44-f30a6294adc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>cleanliness</th>\n",
              "      <th>rooms</th>\n",
              "      <th>service</th>\n",
              "      <th>value</th>\n",
              "      <th>num_cities</th>\n",
              "      <th>num_helpful_votes</th>\n",
              "      <th>num_reviews</th>\n",
              "      <th>num_type_reviews</th>\n",
              "      <th>id</th>\n",
              "      <th>offering_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10050.000000</td>\n",
              "      <td>10050.000000</td>\n",
              "      <td>10050.000000</td>\n",
              "      <td>10050.000000</td>\n",
              "      <td>10050.000000</td>\n",
              "      <td>7682.000000</td>\n",
              "      <td>10050.000000</td>\n",
              "      <td>9993.000000</td>\n",
              "      <td>6444.000000</td>\n",
              "      <td>1.005000e+04</td>\n",
              "      <td>1.005000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.038706</td>\n",
              "      <td>4.294726</td>\n",
              "      <td>4.012736</td>\n",
              "      <td>4.165473</td>\n",
              "      <td>3.949751</td>\n",
              "      <td>12.655038</td>\n",
              "      <td>1.019801</td>\n",
              "      <td>17.448714</td>\n",
              "      <td>14.027933</td>\n",
              "      <td>9.109240e+07</td>\n",
              "      <td>3.099200e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.104904</td>\n",
              "      <td>1.010100</td>\n",
              "      <td>1.101676</td>\n",
              "      <td>1.128248</td>\n",
              "      <td>1.145136</td>\n",
              "      <td>14.029587</td>\n",
              "      <td>2.313198</td>\n",
              "      <td>26.746115</td>\n",
              "      <td>16.229405</td>\n",
              "      <td>4.854196e+07</td>\n",
              "      <td>4.394021e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.978530e+05</td>\n",
              "      <td>7.257200e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.819406e+07</td>\n",
              "      <td>8.759000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.184954e+08</td>\n",
              "      <td>1.095195e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.318665e+08</td>\n",
              "      <td>2.496960e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>472.000000</td>\n",
              "      <td>259.000000</td>\n",
              "      <td>1.477548e+08</td>\n",
              "      <td>3.236579e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af9d2c4f-6791-402f-8d44-f30a6294adc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af9d2c4f-6791-402f-8d44-f30a6294adc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af9d2c4f-6791-402f-8d44-f30a6294adc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data.location.isin(['0.0','1.0','2.0','3.0','4.0','5.0'])]"
      ],
      "metadata": {
        "id": "oVI8K81zr0sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.location.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgX0PiTLUMwe",
        "outputId": "9a1a1b16-4039-4adf-f780-4186f45e9586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['5.0', '5.0', '4.0', ..., '3.0', '5.0', '4.0'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cls = ['cleanliness','location','rooms','service','value']\n",
        "for cl in cls:\n",
        "  data[cl] = np.asarray(data[cl]).astype(np.float64)\n",
        "\n",
        "for cl in cls:\n",
        "  print(cls,data[data[cl]==1.0].shape,data[data[cl]==2.0].shape,data[data[cl]==3.0].shape,data[data[cl]==4.0].shape,data[data[cl]==5.0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBDyItihTmJk",
        "outputId": "642fd246-b607-455e-a73e-a8cb6f2799bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cleanliness', 'location', 'rooms', 'service', 'value'] (307, 19) (349, 19) (991, 19) (2497, 19) (5524, 19)\n",
            "['cleanliness', 'location', 'rooms', 'service', 'value'] (137, 19) (251, 19) (934, 19) (2360, 19) (5986, 19)\n",
            "['cleanliness', 'location', 'rooms', 'service', 'value'] (413, 19) (579, 19) (1556, 19) (2978, 19) (4142, 19)\n",
            "['cleanliness', 'location', 'rooms', 'service', 'value'] (486, 19) (446, 19) (1160, 19) (2341, 19) (5235, 19)\n",
            "['cleanliness', 'location', 'rooms', 'service', 'value'] (522, 19) (610, 19) (1586, 19) (3009, 19) (3941, 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['location'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjjvsJByr2XA",
        "outputId": "6a2b7e23-1b52-4a58-b4b3-4eaafec9a361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5., 4., 3., 1., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ord_enc = OrdinalEncoder()\n",
        "data['offering_id'] =ord_enc.fit_transform(data['offering_id'].values.reshape(-1, 1)).reshape(1,-1)[0]\n",
        "data['user_id'] =ord_enc.fit_transform(data['user_id'].values.reshape(-1, 1)).reshape(1,-1)[0]"
      ],
      "metadata": {
        "id": "KcqIewn6pGSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "rXmSzn74pd8S",
        "outputId": "d546139c-a506-4d9e-de0e-70c575025a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   overall  cleanliness  location  rooms  service  value  \\\n",
              "0      4.0          5.0       5.0    5.0      4.0    3.0   \n",
              "1      4.0          5.0       5.0    5.0      4.0    5.0   \n",
              "2      5.0          5.0       4.0    5.0      5.0    3.0   \n",
              "3      4.0          4.0       3.0    4.0      4.0    4.0   \n",
              "4      4.0          4.0       4.0    5.0      4.0    4.0   \n",
              "\n",
              "                                             title  \\\n",
              "0  “Its the best of the Andaz Brand in the US....”   \n",
              "1                          “Stunningly Wonderful!”   \n",
              "2                              “Unexpectedly good”   \n",
              "3           “Pleasant enough, but a bit overrated”   \n",
              "4                                   “nice suprise”   \n",
              "\n",
              "                                                text             username  \\\n",
              "0  I have stayed at each of the US Andaz properti...            JamesE339   \n",
              "1  Other hotels in NYC that are space challenged ...             romadaro   \n",
              "2  Campus hotels are a little unpredictable, but ...            Grotshops   \n",
              "3  For our most recent ever-so-brief New York vis...  pillowsofwanderlust   \n",
              "4  Booked this hotel thinking it was another Hilt...     beatricepugzilla   \n",
              "\n",
              "   num_cities  num_helpful_votes  num_reviews  num_type_reviews         id  \\\n",
              "0        34.0                  0        104.0              49.0  147612823   \n",
              "1        70.0                  5        103.0              85.0  147531970   \n",
              "2        35.0                  0         96.0              51.0  140624089   \n",
              "3        20.0                  2         57.0              49.0  145940048   \n",
              "4        28.0                  2         41.0              36.0  127060765   \n",
              "\n",
              "      date_stayed  offering_id                date  via_mobile  user_id  \n",
              "0   December 2012       1927.0   December 17, 2012       False    626.0  \n",
              "1   December 2012       1927.0   December 16, 2012       False    677.0  \n",
              "2  September 2012        849.0  September 18, 2012       False    271.0  \n",
              "3   November 2012       1929.0   November 22, 2012       False    224.0  \n",
              "4      March 2012        849.0       April 1, 2012       False    583.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac1adc04-fabc-45ca-9bf3-56dad981b144\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>cleanliness</th>\n",
              "      <th>location</th>\n",
              "      <th>rooms</th>\n",
              "      <th>service</th>\n",
              "      <th>value</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>username</th>\n",
              "      <th>num_cities</th>\n",
              "      <th>num_helpful_votes</th>\n",
              "      <th>num_reviews</th>\n",
              "      <th>num_type_reviews</th>\n",
              "      <th>id</th>\n",
              "      <th>date_stayed</th>\n",
              "      <th>offering_id</th>\n",
              "      <th>date</th>\n",
              "      <th>via_mobile</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>“Its the best of the Andaz Brand in the US....”</td>\n",
              "      <td>I have stayed at each of the US Andaz properti...</td>\n",
              "      <td>JamesE339</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>147612823</td>\n",
              "      <td>December 2012</td>\n",
              "      <td>1927.0</td>\n",
              "      <td>December 17, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>626.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>“Stunningly Wonderful!”</td>\n",
              "      <td>Other hotels in NYC that are space challenged ...</td>\n",
              "      <td>romadaro</td>\n",
              "      <td>70.0</td>\n",
              "      <td>5</td>\n",
              "      <td>103.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>147531970</td>\n",
              "      <td>December 2012</td>\n",
              "      <td>1927.0</td>\n",
              "      <td>December 16, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>677.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>“Unexpectedly good”</td>\n",
              "      <td>Campus hotels are a little unpredictable, but ...</td>\n",
              "      <td>Grotshops</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>140624089</td>\n",
              "      <td>September 2012</td>\n",
              "      <td>849.0</td>\n",
              "      <td>September 18, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>271.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>“Pleasant enough, but a bit overrated”</td>\n",
              "      <td>For our most recent ever-so-brief New York vis...</td>\n",
              "      <td>pillowsofwanderlust</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>57.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>145940048</td>\n",
              "      <td>November 2012</td>\n",
              "      <td>1929.0</td>\n",
              "      <td>November 22, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>224.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>“nice suprise”</td>\n",
              "      <td>Booked this hotel thinking it was another Hilt...</td>\n",
              "      <td>beatricepugzilla</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2</td>\n",
              "      <td>41.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>127060765</td>\n",
              "      <td>March 2012</td>\n",
              "      <td>849.0</td>\n",
              "      <td>April 1, 2012</td>\n",
              "      <td>False</td>\n",
              "      <td>583.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac1adc04-fabc-45ca-9bf3-56dad981b144')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac1adc04-fabc-45ca-9bf3-56dad981b144 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac1adc04-fabc-45ca-9bf3-56dad981b144');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6HlQbKnG7Px",
        "outputId": "6ea82d6f-a290-4c72-b6c7-41782e14aab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9668, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_users = len(data.user_id.unique())\n",
        "nb_hotels = len(data.offering_id.unique())\n",
        "nb_users, nb_hotels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_43cfoTbf5MM",
        "outputId": "51ba5489-ab70-475d-b886-9d8aae6fc7a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(868, 1985)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data,test_size=0.2,random_state=123)"
      ],
      "metadata": {
        "id": "BlDHchihnXqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "user_input = Input(shape=(1,), name = 'user_input')\n",
        "embed_user = Embedding(input_dim=nb_users, output_dim=64, input_length=1)(user_input)\n",
        "embed_user = Flatten()(embed_user)\n",
        "\n",
        "\n",
        "hotel_input = Input(shape=(1,), name = 'item_input')\n",
        "embed_hotel = Embedding(input_dim=nb_hotels, output_dim=64, input_length=1)(hotel_input)\n",
        "embed_hotel = Flatten()(embed_hotel)\n",
        "\n",
        "layers0 = concatenate([embed_user,embed_hotel])\n",
        "hidden1 = Dense(8,activation='relu')(layers0)\n",
        "out = Dense(5)(hidden1)"
      ],
      "metadata": {
        "id": "-GKpYjktgGPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[user_input, hotel_input], \n",
        "                  outputs=out)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdsUrBDlk-Mb",
        "outputId": "d14e4b16-9570-4417-c668-0dad0e9a26a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " user_input (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " item_input (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 64)        55552       ['user_input[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 64)        127040      ['item_input[0][0]']             \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 64)           0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 64)           0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128)          0           ['flatten[0][0]',                \n",
            "                                                                  'flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 8)            1032        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 5)            45          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 183,669\n",
            "Trainable params: 183,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, to_file='img.png', show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "8ZA4IB1Hmqib",
        "outputId": "a85156fa-f509-4724-8bf2-27120822a334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='mae',metrics=['mae'])"
      ],
      "metadata": {
        "id": "zH4lyN6jnR9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_data[['cleanliness','location','rooms','service','value']].values\n",
        "y_test = test_data[['cleanliness','location','rooms','service','value']].values\n",
        "model.fit([train_data.user_id.values,train_data.offering_id.values],y,\n",
        "          \n",
        "          epochs=20,batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbGVBdRan-zp",
        "outputId": "3dbfc3ce-49dc-43bd-f01c-7a08ad0504b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "61/61 [==============================] - 5s 6ms/step - loss: 4.0831 - mae: 4.0831\n",
            "Epoch 2/20\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 3.3497 - mae: 3.3497\n",
            "Epoch 3/20\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 1.8311 - mae: 1.8311\n",
            "Epoch 4/20\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 1.2024 - mae: 1.2024\n",
            "Epoch 5/20\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.8694 - mae: 0.8694\n",
            "Epoch 6/20\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.6980 - mae: 0.6980\n",
            "Epoch 7/20\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.6729 - mae: 0.6729\n",
            "Epoch 8/20\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.6620 - mae: 0.6620\n",
            "Epoch 9/20\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.6544 - mae: 0.6544\n",
            "Epoch 10/20\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.6487 - mae: 0.6487\n",
            "Epoch 11/20\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.6459 - mae: 0.6459\n",
            "Epoch 12/20\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.6406 - mae: 0.6406\n",
            "Epoch 13/20\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.6375 - mae: 0.6375\n",
            "Epoch 14/20\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.6329 - mae: 0.6329\n",
            "Epoch 15/20\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.6299 - mae: 0.6299\n",
            "Epoch 16/20\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.6267 - mae: 0.6267\n",
            "Epoch 17/20\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.6223 - mae: 0.6223\n",
            "Epoch 18/20\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.6182 - mae: 0.6182\n",
            "Epoch 19/20\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.6126 - mae: 0.6126\n",
            "Epoch 20/20\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.6074 - mae: 0.6074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f721c24ab50>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict([test_data.user_id.values,test_data.offering_id.values])"
      ],
      "metadata": {
        "id": "2Ah0nnk_oboY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "LD5pU96Qo338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4a0466-888c-456d-929a-6885ad92b71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.0451503, 4.8897796, 4.953079 , 4.9758763, 4.9981046],\n",
              "       [5.0089993, 5.1540766, 5.0349545, 5.0064607, 5.016122 ],\n",
              "       [3.52792  , 4.0056405, 3.2835624, 4.0630794, 3.8262506],\n",
              "       ...,\n",
              "       [4.2515516, 4.2676435, 3.832677 , 4.093675 , 3.6457837],\n",
              "       [4.637274 , 4.7180963, 4.373731 , 4.560032 , 4.250019 ],\n",
              "       [4.2416983, 4.8441415, 4.282373 , 4.8429885, 4.853967 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "mae(y_test,pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUHmbMh7Iqko",
        "outputId": "a2f17926-57f9-4225-87f6-be45a695fc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8805585702116512"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wTh2rx5GJDp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agg model"
      ],
      "metadata": {
        "id": "oPyH-voNujRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp_agg = Input(shape=(5,), name = 'creteria_input')\n",
        "agg = Dense(64,activation='relu')(inp_agg)\n",
        "agg = Dropout(0.2)(agg)\n",
        "agg = Dense(128,activation='relu')(inp_agg)\n",
        "agg = Dropout(0.3)(agg)\n",
        "agg = Dense(64,activation='relu')(inp_agg)\n",
        "agg = Dropout(0.2)(agg)\n",
        "agg = Dense(32,activation='relu')(agg)\n",
        "agg = Dropout(0.2)(agg)\n",
        "\n",
        "out= Dense(1,activation='relu')(agg)\n",
        "\n",
        "agg_model = Model(inputs=inp_agg, \n",
        "                  outputs=out)\n",
        "\n",
        "agg_model.compile(optimizer='adam',loss='mae',metrics=['mae'])"
      ],
      "metadata": {
        "id": "sUxdGaQlulYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#agg_train_inp = model.predict([train_data.user_id.values,train_data.offering_id.values])\n",
        "train_out = train_data.overall.values"
      ],
      "metadata": {
        "id": "bTbwfATdvZxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agg_model.fit(y,train_out,validation_split=0.2,epochs=20,batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebH26m0nvvkc",
        "outputId": "ee68b94f-ac55-4435-f537-e8a7d4d0d8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "97/97 [==============================] - 1s 5ms/step - loss: 1.0914 - mae: 1.0914 - val_loss: 0.3857 - val_mae: 0.3857\n",
            "Epoch 2/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.7150 - mae: 0.7150 - val_loss: 0.3885 - val_mae: 0.3885\n",
            "Epoch 3/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6690 - mae: 0.6690 - val_loss: 0.3896 - val_mae: 0.3896\n",
            "Epoch 4/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6554 - mae: 0.6554 - val_loss: 0.3972 - val_mae: 0.3972\n",
            "Epoch 5/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6244 - mae: 0.6244 - val_loss: 0.4178 - val_mae: 0.4178\n",
            "Epoch 6/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6192 - mae: 0.6192 - val_loss: 0.3444 - val_mae: 0.3444\n",
            "Epoch 7/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6139 - mae: 0.6139 - val_loss: 0.4373 - val_mae: 0.4373\n",
            "Epoch 8/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6106 - mae: 0.6106 - val_loss: 0.4005 - val_mae: 0.4005\n",
            "Epoch 9/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5979 - mae: 0.5979 - val_loss: 0.4795 - val_mae: 0.4795\n",
            "Epoch 10/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5954 - mae: 0.5954 - val_loss: 0.4690 - val_mae: 0.4690\n",
            "Epoch 11/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5936 - mae: 0.5936 - val_loss: 0.3994 - val_mae: 0.3994\n",
            "Epoch 12/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5882 - mae: 0.5882 - val_loss: 0.3941 - val_mae: 0.3941\n",
            "Epoch 13/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5834 - mae: 0.5834 - val_loss: 0.4423 - val_mae: 0.4423\n",
            "Epoch 14/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5789 - mae: 0.5789 - val_loss: 0.3538 - val_mae: 0.3538\n",
            "Epoch 15/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5714 - mae: 0.5714 - val_loss: 0.3675 - val_mae: 0.3675\n",
            "Epoch 16/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5734 - mae: 0.5734 - val_loss: 0.4045 - val_mae: 0.4045\n",
            "Epoch 17/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5681 - mae: 0.5681 - val_loss: 0.4227 - val_mae: 0.4227\n",
            "Epoch 18/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5668 - mae: 0.5668 - val_loss: 0.3621 - val_mae: 0.3621\n",
            "Epoch 19/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5656 - mae: 0.5656 - val_loss: 0.3854 - val_mae: 0.3854\n",
            "Epoch 20/20\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5676 - mae: 0.5676 - val_loss: 0.3987 - val_mae: 0.3987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71f27bad90>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg_test_inp = model.predict([test_data.user_id.values,test_data.offering_id.values])\n",
        "test_out = test_data.overall.values"
      ],
      "metadata": {
        "id": "uVnqUibNxfAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "mae(agg_model.predict(agg_test_inp),test_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlZLi5qaxpUB",
        "outputId": "32479e9e-172b-43fc-fd94-a05a0960733f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8555902399531071"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kfold"
      ],
      "metadata": {
        "id": "rh-klyz4OXjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model(arch):\n",
        "  user_input = Input(shape=(1,), name = 'user_input')\n",
        "  embed_user = Embedding(input_dim=nb_users, output_dim=64, input_length=1)(user_input)\n",
        "  embed_user = Flatten()(embed_user)\n",
        "\n",
        "\n",
        "  hotel_input = Input(shape=(1,), name = 'item_input')\n",
        "  embed_hotel = Embedding(input_dim=nb_hotels, output_dim=64, input_length=1)(hotel_input)\n",
        "  embed_hotel = Flatten()(embed_hotel)\n",
        "\n",
        "  layers0 = concatenate([embed_user,embed_hotel])\n",
        "\n",
        "  if len(arch)>1:\n",
        "\n",
        "    hidden = Dense(arch[0],activation='relu')(layers0)\n",
        "\n",
        "    for j in range(1,len(arch)):\n",
        "      hidden = Dense(arch[j],activation='relu')(hidden)\n",
        "  else:\n",
        "    hidden = Dense(8,activation='relu')(layers0) \n",
        "\n",
        "  out = Dense(5)(hidden)\n",
        "  model = Model(inputs=[user_input, hotel_input], \n",
        "                  outputs=out)\n",
        "  \n",
        "  model.compile(optimizer='adam',loss='mae',metrics=['mae'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "BxiTr5roPvG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agg_():\n",
        "  inp_agg = Input(shape=(5,), name = 'creteria_input')\n",
        "  agg = Dense(64,activation='relu')(inp_agg)\n",
        "  agg = Dropout(0.2)(agg)\n",
        "  agg = Dense(128,activation='relu')(inp_agg)\n",
        "  agg = Dropout(0.3)(agg)\n",
        "  agg = Dense(64,activation='relu')(inp_agg)\n",
        "  agg = Dropout(0.2)(agg)\n",
        "  agg = Dense(32,activation='relu')(agg)\n",
        "  agg = Dropout(0.2)(agg)\n",
        "\n",
        "  out= Dense(1,activation='relu')(agg)\n",
        "\n",
        "  agg_model = Model(inputs=inp_agg, \n",
        "                    outputs=out)\n",
        "\n",
        "  agg_model.compile(optimizer='adam',loss='mae',metrics=['mae'])\n",
        "  \n",
        "  return agg_model"
      ],
      "metadata": {
        "id": "TRJf0tZnzrjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "kf = KFold(n_splits=5,random_state=24,shuffle=True)\n",
        "\n",
        "mae_hist = []\n",
        "mae_cleanliness = []\n",
        "mae_loc = []\n",
        "mae_rooms = []\n",
        "mae_srv = []\n",
        "\n",
        "mae_value = []\n",
        "\n",
        "rmse_hist = []\n",
        "rmse_cleanliness = []\n",
        "rmse_loc = []\n",
        "rmse_rooms = []\n",
        "rmse_srv = []\n",
        "\n",
        "rmse_value = []\n",
        "\n",
        "agg_mae = []\n",
        "agg_rmse = []\n",
        "\n",
        "\n",
        "archi = [[8],[16,8],[32,16,8],[64,32,16,8],[128,64,32,16,8],[256,128,64,32,16,8]]\n",
        "x_user_id = data.user_id.values\n",
        "x_hotel_id = data.offering_id.values\n",
        "y = data[['cleanliness','location','rooms','service','value']].values\n",
        "over = data['overall'].values\n",
        "\n",
        "for arch in archi:\n",
        "  print(\"\\n archi \",arch,\"\\n\")\n",
        "\n",
        "  i = 1\n",
        "\n",
        "  tmp_mae_cleanliness = []\n",
        "  tmp_mae_loc = []\n",
        "  tmp_mae_rooms = []\n",
        "  tmp_mae_srv = []\n",
        "\n",
        "  tmp_mae_value = []\n",
        "  tmp_mae_hist = []\n",
        "\n",
        "  tmp_rmse_cleanliness = []\n",
        "  tmp_rmse_loc = []\n",
        "  tmp_rmse_rooms = []\n",
        "  tmp_rmse_srv = []\n",
        "\n",
        "  tmp_rmse_value = []\n",
        "  tmp_rmse_hist = []\n",
        "  tmp_agg_mae = []\n",
        "  tmp_agg_rmse = []\n",
        "\n",
        "  for train_index, test_index in kf.split(x_user_id):\n",
        "    print(\"\\n\\n FOLD\\n\",i,\"\\ntrain ncf\\n\")\n",
        "\n",
        "    i+=1\n",
        "\n",
        "    X_user_train, X_user_test = x_user_id[train_index], x_user_id[test_index]\n",
        "    X_hotel_train, X_hotel_test = x_hotel_id[train_index], x_hotel_id[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    over_train , over_test = over[train_index], over[test_index]\n",
        "\n",
        "\n",
        "    model = init_model(arch)\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    model.fit([X_user_train,X_hotel_train],y_train,epochs=15,batch_size=128,validation_split=0.2,callbacks=[callback])\n",
        "\n",
        "    pred = model.predict([X_user_test,X_hotel_test])\n",
        "\n",
        "\n",
        "    \n",
        "    tmp_mae_cleanliness.append(mae(y_test[:,0],pred[:,0]))\n",
        "    tmp_mae_loc.append(mae(y_test[:,1],pred[:,1]))\n",
        "    tmp_mae_rooms.append(mae(y_test[:,2],pred[:,2]))\n",
        "    tmp_mae_srv.append(mae(y_test[:,3],pred[:,3]))\n",
        "\n",
        "    tmp_mae_value.append(mae(y_test[:,4],pred[:,4]))\n",
        "\n",
        "    tmp_mae_hist.append(mae(y_test,pred))\n",
        "\n",
        "\n",
        "    tmp_rmse_cleanliness.append(mse(y_test[:,0],pred[:,0], squared=False))\n",
        "    tmp_rmse_loc.append(mse(y_test[:,1],pred[:,1], squared=False))\n",
        "    tmp_rmse_rooms.append(mse(y_test[:,2],pred[:,2], squared=False))\n",
        "    tmp_rmse_srv.append(mse(y_test[:,3],pred[:,3], squared=False))\n",
        "    \n",
        "    tmp_rmse_value.append(mse(y_test[:,4],pred[:,4], squared=False))\n",
        "\n",
        "    tmp_rmse_hist.append(mse(y_test,pred, squared=False))\n",
        "\n",
        "\n",
        "\n",
        "    agg_model = agg_()\n",
        "\n",
        "    #agg_train_inp = model.predict([X_user_train,X_hotel_train])\n",
        "    print('\\n train agg model \\n')\n",
        "    agg_model.fit(y_train,over_train,validation_split=0.1,epochs=20,batch_size=64)\n",
        "\n",
        "    agg_test_inp = model.predict([X_user_test,X_hotel_test])\n",
        "\n",
        "    tmp_agg_mae.append(mae(agg_model.predict(agg_test_inp),over_test))\n",
        "    tmp_agg_rmse.append(mse(agg_model.predict(agg_test_inp),over_test,squared=False))\n",
        "\n",
        "  \n",
        "  mae_cleanliness.append(np.mean(tmp_mae_cleanliness))\n",
        "  mae_loc.append(np.mean(tmp_mae_loc))\n",
        "  mae_rooms.append(np.mean(tmp_mae_rooms))\n",
        "  mae_srv.append(np.mean(tmp_mae_srv))\n",
        "  \n",
        "  mae_value.append(np.mean(tmp_mae_value))\n",
        "  mae_hist.append(np.mean(tmp_mae_hist))\n",
        "    \n",
        "  rmse_cleanliness.append(np.mean(tmp_rmse_cleanliness))\n",
        "  rmse_loc.append(np.mean(tmp_rmse_loc))\n",
        "  rmse_rooms.append(np.mean(tmp_rmse_rooms))\n",
        "  rmse_srv.append(np.mean(tmp_rmse_srv))\n",
        " \n",
        "  rmse_value.append(np.mean(tmp_rmse_value))\n",
        "  rmse_hist.append(np.mean(tmp_rmse_hist))\n",
        "\n",
        "  agg_mae.append(np.mean(tmp_agg_mae))\n",
        "  agg_rmse.append(np.mean(tmp_agg_rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10deIWM_OYYl",
        "outputId": "32aafde7-28fa-4339-afef-db54ac5e08a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " archi  [8] \n",
            "\n",
            "\n",
            "\n",
            " FOLD\n",
            " 1 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 4.1007 - mae: 4.1007 - val_loss: 4.0911 - val_mae: 4.0911\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.6787 - mae: 3.6787 - val_loss: 3.6133 - val_mae: 3.6133\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.3575 - mae: 2.3575 - val_loss: 2.5340 - val_mae: 2.5340\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.1834 - mae: 1.1834 - val_loss: 2.0319 - val_mae: 2.0319\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.8184 - mae: 0.8184 - val_loss: 1.8410 - val_mae: 1.8410\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.7140 - mae: 0.7140 - val_loss: 1.7747 - val_mae: 1.7747\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6846 - mae: 0.6846 - val_loss: 1.7593 - val_mae: 1.7593\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6670 - mae: 0.6670 - val_loss: 1.7336 - val_mae: 1.7336\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6558 - mae: 0.6558 - val_loss: 1.7250 - val_mae: 1.7250\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6459 - mae: 0.6459 - val_loss: 1.7496 - val_mae: 1.7496\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6393 - mae: 0.6393 - val_loss: 1.7480 - val_mae: 1.7480\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6340 - mae: 0.6340 - val_loss: 1.7461 - val_mae: 1.7461\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 0.9935 - mae: 0.9935 - val_loss: 0.6998 - val_mae: 0.6998\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7219 - mae: 0.7219 - val_loss: 0.4645 - val_mae: 0.4645\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6540 - mae: 0.6540 - val_loss: 0.4977 - val_mae: 0.4977\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6350 - mae: 0.6350 - val_loss: 0.6006 - val_mae: 0.6006\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6163 - mae: 0.6163 - val_loss: 0.5161 - val_mae: 0.5161\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5988 - mae: 0.5988 - val_loss: 0.5940 - val_mae: 0.5940\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6018 - mae: 0.6018 - val_loss: 0.5938 - val_mae: 0.5938\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5879 - mae: 0.5879 - val_loss: 0.5217 - val_mae: 0.5217\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5799 - mae: 0.5799 - val_loss: 0.5726 - val_mae: 0.5726\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5673 - mae: 0.5673 - val_loss: 0.5797 - val_mae: 0.5797\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5812 - mae: 0.5812 - val_loss: 0.5971 - val_mae: 0.5971\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5701 - mae: 0.5701 - val_loss: 0.5039 - val_mae: 0.5039\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5587 - mae: 0.5587 - val_loss: 0.5579 - val_mae: 0.5579\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5557 - mae: 0.5557 - val_loss: 0.6231 - val_mae: 0.6231\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5498 - mae: 0.5498 - val_loss: 0.4978 - val_mae: 0.4978\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5515 - mae: 0.5515 - val_loss: 0.5046 - val_mae: 0.5046\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5395 - mae: 0.5395 - val_loss: 0.5129 - val_mae: 0.5129\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5388 - mae: 0.5388 - val_loss: 0.6067 - val_mae: 0.6067\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5345 - mae: 0.5345 - val_loss: 0.5843 - val_mae: 0.5843\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5287 - mae: 0.5287 - val_loss: 0.5473 - val_mae: 0.5473\n",
            "\n",
            "\n",
            " FOLD\n",
            " 2 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 4.0375 - mae: 4.0375 - val_loss: 4.0015 - val_mae: 4.0015\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.3523 - mae: 3.3523 - val_loss: 3.3322 - val_mae: 3.3322\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.0222 - mae: 2.0222 - val_loss: 2.5021 - val_mae: 2.5021\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 1.3765 - mae: 1.3765 - val_loss: 2.1794 - val_mae: 2.1794\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.9731 - mae: 0.9731 - val_loss: 1.9430 - val_mae: 1.9430\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.7677 - mae: 0.7677 - val_loss: 1.8394 - val_mae: 1.8394\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6964 - mae: 0.6964 - val_loss: 1.8017 - val_mae: 1.8017\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6717 - mae: 0.6717 - val_loss: 1.7955 - val_mae: 1.7955\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6568 - mae: 0.6568 - val_loss: 1.7839 - val_mae: 1.7839\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6490 - mae: 0.6490 - val_loss: 1.7724 - val_mae: 1.7724\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6444 - mae: 0.6444 - val_loss: 1.7644 - val_mae: 1.7644\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6382 - mae: 0.6382 - val_loss: 1.7776 - val_mae: 1.7776\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6317 - mae: 0.6317 - val_loss: 1.7524 - val_mae: 1.7524\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6273 - mae: 0.6273 - val_loss: 1.7475 - val_mae: 1.7475\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6230 - mae: 0.6230 - val_loss: 1.7512 - val_mae: 1.7512\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.1935 - mae: 1.1935 - val_loss: 0.4355 - val_mae: 0.4355\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7581 - mae: 0.7581 - val_loss: 0.4646 - val_mae: 0.4646\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6978 - mae: 0.6978 - val_loss: 0.3999 - val_mae: 0.3999\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6676 - mae: 0.6676 - val_loss: 0.4629 - val_mae: 0.4629\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6363 - mae: 0.6363 - val_loss: 0.4744 - val_mae: 0.4744\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6458 - mae: 0.6458 - val_loss: 0.4318 - val_mae: 0.4318\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6333 - mae: 0.6333 - val_loss: 0.5206 - val_mae: 0.5206\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6261 - mae: 0.6261 - val_loss: 0.4500 - val_mae: 0.4500\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6151 - mae: 0.6151 - val_loss: 0.5479 - val_mae: 0.5479\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6172 - mae: 0.6172 - val_loss: 0.4418 - val_mae: 0.4418\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5839 - mae: 0.5839 - val_loss: 0.3876 - val_mae: 0.3876\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5903 - mae: 0.5903 - val_loss: 0.4214 - val_mae: 0.4214\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5736 - mae: 0.5736 - val_loss: 0.4172 - val_mae: 0.4172\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5676 - mae: 0.5676 - val_loss: 0.5880 - val_mae: 0.5880\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5631 - mae: 0.5631 - val_loss: 0.4469 - val_mae: 0.4469\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5623 - mae: 0.5623 - val_loss: 0.5030 - val_mae: 0.5030\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5574 - mae: 0.5574 - val_loss: 0.4603 - val_mae: 0.4603\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5530 - mae: 0.5530 - val_loss: 0.4478 - val_mae: 0.4478\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5388 - mae: 0.5388 - val_loss: 0.5191 - val_mae: 0.5191\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5411 - mae: 0.5411 - val_loss: 0.4472 - val_mae: 0.4472\n",
            "\n",
            "\n",
            " FOLD\n",
            " 3 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 4.1152 - mae: 4.1152 - val_loss: 4.1343 - val_mae: 4.1343\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.8858 - mae: 3.8858 - val_loss: 3.8890 - val_mae: 3.8890\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.2060 - mae: 3.2060 - val_loss: 3.3232 - val_mae: 3.3232\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 2.2494 - mae: 2.2494 - val_loss: 2.7715 - val_mae: 2.7715\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 1.7993 - mae: 1.7993 - val_loss: 2.5469 - val_mae: 2.5469\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 1.5006 - mae: 1.5006 - val_loss: 2.3388 - val_mae: 2.3388\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 1.2594 - mae: 1.2594 - val_loss: 2.1774 - val_mae: 2.1774\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 1.0092 - mae: 1.0092 - val_loss: 1.9389 - val_mae: 1.9389\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7317 - mae: 0.7317 - val_loss: 1.8072 - val_mae: 1.8072\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6648 - mae: 0.6648 - val_loss: 1.7957 - val_mae: 1.7957\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6524 - mae: 0.6524 - val_loss: 1.7812 - val_mae: 1.7812\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6462 - mae: 0.6462 - val_loss: 1.7861 - val_mae: 1.7861\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6399 - mae: 0.6399 - val_loss: 1.7657 - val_mae: 1.7657\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6355 - mae: 0.6355 - val_loss: 1.7692 - val_mae: 1.7692\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6335 - mae: 0.6335 - val_loss: 1.7755 - val_mae: 1.7755\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.1061 - mae: 1.1061 - val_loss: 0.4927 - val_mae: 0.4927\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7081 - mae: 0.7081 - val_loss: 0.5118 - val_mae: 0.5118\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6495 - mae: 0.6495 - val_loss: 0.5086 - val_mae: 0.5086\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6258 - mae: 0.6258 - val_loss: 0.3961 - val_mae: 0.3961\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6238 - mae: 0.6238 - val_loss: 0.3944 - val_mae: 0.3944\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6037 - mae: 0.6037 - val_loss: 0.4725 - val_mae: 0.4725\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5990 - mae: 0.5990 - val_loss: 0.5335 - val_mae: 0.5335\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5897 - mae: 0.5897 - val_loss: 0.4646 - val_mae: 0.4646\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5904 - mae: 0.5904 - val_loss: 0.4099 - val_mae: 0.4099\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5808 - mae: 0.5808 - val_loss: 0.4224 - val_mae: 0.4224\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5787 - mae: 0.5787 - val_loss: 0.4260 - val_mae: 0.4260\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5856 - mae: 0.5856 - val_loss: 0.4886 - val_mae: 0.4886\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5687 - mae: 0.5687 - val_loss: 0.3583 - val_mae: 0.3583\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5640 - mae: 0.5640 - val_loss: 0.4419 - val_mae: 0.4419\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5619 - mae: 0.5619 - val_loss: 0.4548 - val_mae: 0.4548\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5502 - mae: 0.5502 - val_loss: 0.4867 - val_mae: 0.4867\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5496 - mae: 0.5496 - val_loss: 0.4579 - val_mae: 0.4579\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5480 - mae: 0.5480 - val_loss: 0.4182 - val_mae: 0.4182\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5533 - mae: 0.5533 - val_loss: 0.4254 - val_mae: 0.4254\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5316 - mae: 0.5316 - val_loss: 0.4680 - val_mae: 0.4680\n",
            "\n",
            "\n",
            " FOLD\n",
            " 4 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 4.1273 - mae: 4.1273 - val_loss: 4.1347 - val_mae: 4.1347\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.8874 - mae: 3.8874 - val_loss: 3.8738 - val_mae: 3.8738\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1386 - mae: 3.1386 - val_loss: 3.2064 - val_mae: 3.2064\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 2.1737 - mae: 2.1737 - val_loss: 2.6794 - val_mae: 2.6794\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.6806 - mae: 1.6806 - val_loss: 2.3815 - val_mae: 2.3815\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.3508 - mae: 1.3508 - val_loss: 2.1672 - val_mae: 2.1672\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 1.1254 - mae: 1.1254 - val_loss: 2.0175 - val_mae: 2.0175\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.9496 - mae: 0.9496 - val_loss: 1.8915 - val_mae: 1.8915\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7919 - mae: 0.7919 - val_loss: 1.8043 - val_mae: 1.8043\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6895 - mae: 0.6895 - val_loss: 1.7454 - val_mae: 1.7454\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6580 - mae: 0.6580 - val_loss: 1.7316 - val_mae: 1.7316\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6513 - mae: 0.6513 - val_loss: 1.7253 - val_mae: 1.7253\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6470 - mae: 0.6470 - val_loss: 1.7373 - val_mae: 1.7373\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6417 - mae: 0.6417 - val_loss: 1.7217 - val_mae: 1.7217\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6393 - mae: 0.6393 - val_loss: 1.7205 - val_mae: 1.7205\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 6ms/step - loss: 1.5879 - mae: 1.5879 - val_loss: 0.4115 - val_mae: 0.4115\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7386 - mae: 0.7386 - val_loss: 0.4311 - val_mae: 0.4311\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6802 - mae: 0.6802 - val_loss: 0.4843 - val_mae: 0.4843\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6605 - mae: 0.6605 - val_loss: 0.4316 - val_mae: 0.4316\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6408 - mae: 0.6408 - val_loss: 0.3905 - val_mae: 0.3905\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6447 - mae: 0.6447 - val_loss: 0.4616 - val_mae: 0.4616\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6322 - mae: 0.6322 - val_loss: 0.3963 - val_mae: 0.3963\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6160 - mae: 0.6160 - val_loss: 0.4051 - val_mae: 0.4051\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6174 - mae: 0.6174 - val_loss: 0.4418 - val_mae: 0.4418\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6056 - mae: 0.6056 - val_loss: 0.4280 - val_mae: 0.4280\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6059 - mae: 0.6059 - val_loss: 0.4502 - val_mae: 0.4502\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5922 - mae: 0.5922 - val_loss: 0.3829 - val_mae: 0.3829\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5908 - mae: 0.5908 - val_loss: 0.4102 - val_mae: 0.4102\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5948 - mae: 0.5948 - val_loss: 0.4441 - val_mae: 0.4441\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5864 - mae: 0.5864 - val_loss: 0.4163 - val_mae: 0.4163\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5783 - mae: 0.5783 - val_loss: 0.3799 - val_mae: 0.3799\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5837 - mae: 0.5837 - val_loss: 0.4307 - val_mae: 0.4307\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5635 - mae: 0.5635 - val_loss: 0.4471 - val_mae: 0.4471\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5554 - mae: 0.5554 - val_loss: 0.4369 - val_mae: 0.4369\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5456 - mae: 0.5456 - val_loss: 0.4139 - val_mae: 0.4139\n",
            "\n",
            "\n",
            " FOLD\n",
            " 5 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 7ms/step - loss: 4.0509 - mae: 4.0509 - val_loss: 3.9915 - val_mae: 3.9915\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.3287 - mae: 3.3287 - val_loss: 3.2559 - val_mae: 3.2559\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 1.8464 - mae: 1.8464 - val_loss: 2.3118 - val_mae: 2.3118\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.1427 - mae: 1.1427 - val_loss: 2.0296 - val_mae: 2.0296\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.8457 - mae: 0.8457 - val_loss: 1.8372 - val_mae: 1.8372\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7184 - mae: 0.7184 - val_loss: 1.7602 - val_mae: 1.7602\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6830 - mae: 0.6830 - val_loss: 1.7394 - val_mae: 1.7394\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6667 - mae: 0.6667 - val_loss: 1.7214 - val_mae: 1.7214\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6587 - mae: 0.6587 - val_loss: 1.7268 - val_mae: 1.7268\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6528 - mae: 0.6528 - val_loss: 1.7180 - val_mae: 1.7180\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6464 - mae: 0.6464 - val_loss: 1.7213 - val_mae: 1.7213\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6391 - mae: 0.6391 - val_loss: 1.7183 - val_mae: 1.7183\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6354 - mae: 0.6354 - val_loss: 1.7050 - val_mae: 1.7050\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6307 - mae: 0.6307 - val_loss: 1.6906 - val_mae: 1.6906\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6265 - mae: 0.6265 - val_loss: 1.6897 - val_mae: 1.6897\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.2219 - mae: 1.2219 - val_loss: 0.4206 - val_mae: 0.4206\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7395 - mae: 0.7395 - val_loss: 0.4771 - val_mae: 0.4771\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6824 - mae: 0.6824 - val_loss: 0.4910 - val_mae: 0.4910\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6440 - mae: 0.6440 - val_loss: 0.4812 - val_mae: 0.4812\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6148 - mae: 0.6148 - val_loss: 0.4370 - val_mae: 0.4370\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6185 - mae: 0.6185 - val_loss: 0.4315 - val_mae: 0.4315\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6041 - mae: 0.6041 - val_loss: 0.5887 - val_mae: 0.5887\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6013 - mae: 0.6013 - val_loss: 0.4292 - val_mae: 0.4292\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6000 - mae: 0.6000 - val_loss: 0.4394 - val_mae: 0.4394\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5788 - mae: 0.5788 - val_loss: 0.5302 - val_mae: 0.5302\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5790 - mae: 0.5790 - val_loss: 0.4364 - val_mae: 0.4364\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5737 - mae: 0.5737 - val_loss: 0.4617 - val_mae: 0.4617\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5770 - mae: 0.5770 - val_loss: 0.3556 - val_mae: 0.3556\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5583 - mae: 0.5583 - val_loss: 0.3984 - val_mae: 0.3984\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5542 - mae: 0.5542 - val_loss: 0.4218 - val_mae: 0.4218\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5512 - mae: 0.5512 - val_loss: 0.3893 - val_mae: 0.3893\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5544 - mae: 0.5544 - val_loss: 0.4261 - val_mae: 0.4261\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5477 - mae: 0.5477 - val_loss: 0.4331 - val_mae: 0.4331\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5481 - mae: 0.5481 - val_loss: 0.4298 - val_mae: 0.4298\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5458 - mae: 0.5458 - val_loss: 0.4125 - val_mae: 0.4125\n",
            "\n",
            " archi  [16, 8] \n",
            "\n",
            "\n",
            "\n",
            " FOLD\n",
            " 1 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 4.0703 - mae: 4.0703 - val_loss: 4.0064 - val_mae: 4.0064\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2617 - mae: 3.2617 - val_loss: 2.9276 - val_mae: 2.9276\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.7639 - mae: 1.7639 - val_loss: 2.1965 - val_mae: 2.1965\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.1210 - mae: 1.1210 - val_loss: 1.7960 - val_mae: 1.7960\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7863 - mae: 0.7863 - val_loss: 1.6551 - val_mae: 1.6551\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6977 - mae: 0.6977 - val_loss: 1.6462 - val_mae: 1.6462\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6782 - mae: 0.6782 - val_loss: 1.6109 - val_mae: 1.6109\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6690 - mae: 0.6690 - val_loss: 1.6243 - val_mae: 1.6243\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6617 - mae: 0.6617 - val_loss: 1.6221 - val_mae: 1.6221\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6569 - mae: 0.6569 - val_loss: 1.6099 - val_mae: 1.6099\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6521 - mae: 0.6521 - val_loss: 1.5911 - val_mae: 1.5911\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6488 - mae: 0.6488 - val_loss: 1.5785 - val_mae: 1.5785\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6474 - mae: 0.6474 - val_loss: 1.5609 - val_mae: 1.5609\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.6431 - val_loss: 1.5542 - val_mae: 1.5542\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6413 - mae: 0.6413 - val_loss: 1.5419 - val_mae: 1.5419\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 0.9411 - mae: 0.9411 - val_loss: 0.5621 - val_mae: 0.5621\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7143 - mae: 0.7143 - val_loss: 0.3627 - val_mae: 0.3627\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6433 - mae: 0.6433 - val_loss: 0.4003 - val_mae: 0.4003\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6246 - mae: 0.6246 - val_loss: 0.4011 - val_mae: 0.4011\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6157 - mae: 0.6157 - val_loss: 0.5148 - val_mae: 0.5148\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6072 - mae: 0.6072 - val_loss: 0.5001 - val_mae: 0.5001\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5937 - mae: 0.5937 - val_loss: 0.4524 - val_mae: 0.4524\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5730 - mae: 0.5730 - val_loss: 0.3813 - val_mae: 0.3813\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5694 - mae: 0.5694 - val_loss: 0.4309 - val_mae: 0.4309\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5661 - mae: 0.5661 - val_loss: 0.4596 - val_mae: 0.4596\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5617 - mae: 0.5617 - val_loss: 0.3818 - val_mae: 0.3818\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5477 - mae: 0.5477 - val_loss: 0.4099 - val_mae: 0.4099\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5550 - mae: 0.5550 - val_loss: 0.4061 - val_mae: 0.4061\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5470 - mae: 0.5470 - val_loss: 0.4102 - val_mae: 0.4102\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5443 - mae: 0.5443 - val_loss: 0.4062 - val_mae: 0.4062\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5267 - mae: 0.5267 - val_loss: 0.3968 - val_mae: 0.3968\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5352 - mae: 0.5352 - val_loss: 0.3763 - val_mae: 0.3763\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5294 - mae: 0.5294 - val_loss: 0.4609 - val_mae: 0.4609\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5279 - mae: 0.5279 - val_loss: 0.4217 - val_mae: 0.4217\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5168 - mae: 0.5168 - val_loss: 0.4968 - val_mae: 0.4968\n",
            "\n",
            "\n",
            " FOLD\n",
            " 2 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 4.0800 - mae: 4.0800 - val_loss: 4.0262 - val_mae: 4.0262\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2631 - mae: 3.2631 - val_loss: 2.8474 - val_mae: 2.8474\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.4351 - mae: 1.4351 - val_loss: 1.8389 - val_mae: 1.8389\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7956 - mae: 0.7956 - val_loss: 1.6481 - val_mae: 1.6481\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.7155 - mae: 0.7155 - val_loss: 1.6126 - val_mae: 1.6126\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6904 - mae: 0.6904 - val_loss: 1.5685 - val_mae: 1.5685\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6763 - mae: 0.6763 - val_loss: 1.5563 - val_mae: 1.5563\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6656 - mae: 0.6656 - val_loss: 1.5808 - val_mae: 1.5808\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6592 - mae: 0.6592 - val_loss: 1.5558 - val_mae: 1.5558\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6538 - mae: 0.6538 - val_loss: 1.5519 - val_mae: 1.5519\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6492 - mae: 0.6492 - val_loss: 1.5624 - val_mae: 1.5624\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6459 - mae: 0.6459 - val_loss: 1.5585 - val_mae: 1.5585\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6424 - mae: 0.6424 - val_loss: 1.5390 - val_mae: 1.5390\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6373 - mae: 0.6373 - val_loss: 1.5323 - val_mae: 1.5323\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6346 - mae: 0.6346 - val_loss: 1.5103 - val_mae: 1.5103\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.2520 - mae: 1.2520 - val_loss: 0.4027 - val_mae: 0.4027\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7573 - mae: 0.7573 - val_loss: 0.5775 - val_mae: 0.5775\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6773 - mae: 0.6773 - val_loss: 0.4797 - val_mae: 0.4797\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6517 - mae: 0.6517 - val_loss: 0.4982 - val_mae: 0.4982\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6463 - mae: 0.6463 - val_loss: 0.4393 - val_mae: 0.4393\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6337 - mae: 0.6337 - val_loss: 0.5052 - val_mae: 0.5052\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6217 - mae: 0.6217 - val_loss: 0.5376 - val_mae: 0.5376\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6188 - mae: 0.6188 - val_loss: 0.4595 - val_mae: 0.4595\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6150 - mae: 0.6150 - val_loss: 0.4294 - val_mae: 0.4294\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6155 - mae: 0.6155 - val_loss: 0.4726 - val_mae: 0.4726\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6070 - mae: 0.6070 - val_loss: 0.5122 - val_mae: 0.5122\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6012 - mae: 0.6012 - val_loss: 0.5610 - val_mae: 0.5610\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5882 - mae: 0.5882 - val_loss: 0.4783 - val_mae: 0.4783\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5758 - mae: 0.5758 - val_loss: 0.4534 - val_mae: 0.4534\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5657 - mae: 0.5657 - val_loss: 0.6104 - val_mae: 0.6104\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5571 - mae: 0.5571 - val_loss: 0.6535 - val_mae: 0.6535\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5562 - mae: 0.5562 - val_loss: 0.5950 - val_mae: 0.5950\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5520 - mae: 0.5520 - val_loss: 0.5702 - val_mae: 0.5702\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5419 - mae: 0.5419 - val_loss: 0.5010 - val_mae: 0.5010\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5365 - mae: 0.5365 - val_loss: 0.6185 - val_mae: 0.6185\n",
            "\n",
            "\n",
            " FOLD\n",
            " 3 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 4.0922 - mae: 4.0922 - val_loss: 4.0642 - val_mae: 4.0642\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.4662 - mae: 3.4662 - val_loss: 3.1508 - val_mae: 3.1508\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 1.3689 - mae: 1.3689 - val_loss: 1.9110 - val_mae: 1.9110\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7899 - mae: 0.7899 - val_loss: 1.7400 - val_mae: 1.7400\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.7168 - mae: 0.7168 - val_loss: 1.6729 - val_mae: 1.6729\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6869 - mae: 0.6869 - val_loss: 1.6861 - val_mae: 1.6861\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6711 - mae: 0.6711 - val_loss: 1.6831 - val_mae: 1.6831\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6590 - mae: 0.6590 - val_loss: 1.6577 - val_mae: 1.6577\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6539 - mae: 0.6539 - val_loss: 1.6438 - val_mae: 1.6438\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6455 - mae: 0.6455 - val_loss: 1.6395 - val_mae: 1.6395\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6419 - mae: 0.6419 - val_loss: 1.6248 - val_mae: 1.6248\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6359 - mae: 0.6359 - val_loss: 1.6278 - val_mae: 1.6278\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6320 - mae: 0.6320 - val_loss: 1.6037 - val_mae: 1.6037\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6277 - mae: 0.6277 - val_loss: 1.6063 - val_mae: 1.6063\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6246 - mae: 0.6246 - val_loss: 1.5945 - val_mae: 1.5945\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.7151 - mae: 1.7151 - val_loss: 0.5851 - val_mae: 0.5851\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7204 - mae: 0.7204 - val_loss: 0.4865 - val_mae: 0.4865\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6380 - mae: 0.6380 - val_loss: 0.4261 - val_mae: 0.4261\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6286 - mae: 0.6286 - val_loss: 0.3898 - val_mae: 0.3898\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6138 - mae: 0.6138 - val_loss: 0.4262 - val_mae: 0.4262\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6187 - mae: 0.6187 - val_loss: 0.4518 - val_mae: 0.4518\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6202 - mae: 0.6202 - val_loss: 0.4789 - val_mae: 0.4789\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6035 - mae: 0.6035 - val_loss: 0.4554 - val_mae: 0.4554\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5953 - mae: 0.5953 - val_loss: 0.4561 - val_mae: 0.4561\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5876 - mae: 0.5876 - val_loss: 0.5584 - val_mae: 0.5584\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5774 - mae: 0.5774 - val_loss: 0.4359 - val_mae: 0.4359\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5776 - mae: 0.5776 - val_loss: 0.4423 - val_mae: 0.4423\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5728 - mae: 0.5728 - val_loss: 0.5558 - val_mae: 0.5558\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5666 - mae: 0.5666 - val_loss: 0.4156 - val_mae: 0.4156\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5578 - mae: 0.5578 - val_loss: 0.4643 - val_mae: 0.4643\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5610 - mae: 0.5610 - val_loss: 0.6075 - val_mae: 0.6075\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5535 - mae: 0.5535 - val_loss: 0.4765 - val_mae: 0.4765\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5491 - mae: 0.5491 - val_loss: 0.4878 - val_mae: 0.4878\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5426 - mae: 0.5426 - val_loss: 0.5212 - val_mae: 0.5212\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5321 - mae: 0.5321 - val_loss: 0.4944 - val_mae: 0.4944\n",
            "\n",
            "\n",
            " FOLD\n",
            " 4 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 4.0135 - mae: 4.0135 - val_loss: 3.8861 - val_mae: 3.8861\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.7753 - mae: 2.7753 - val_loss: 2.4983 - val_mae: 2.4983\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.4241 - mae: 1.4241 - val_loss: 1.8818 - val_mae: 1.8818\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.8024 - mae: 0.8024 - val_loss: 1.6394 - val_mae: 1.6394\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7222 - mae: 0.7222 - val_loss: 1.6175 - val_mae: 1.6175\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6932 - mae: 0.6932 - val_loss: 1.5925 - val_mae: 1.5925\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6773 - mae: 0.6773 - val_loss: 1.6059 - val_mae: 1.6059\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6694 - mae: 0.6694 - val_loss: 1.5849 - val_mae: 1.5849\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6607 - mae: 0.6607 - val_loss: 1.5860 - val_mae: 1.5860\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6555 - mae: 0.6555 - val_loss: 1.5767 - val_mae: 1.5767\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6486 - mae: 0.6486 - val_loss: 1.5606 - val_mae: 1.5606\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6432 - mae: 0.6432 - val_loss: 1.5611 - val_mae: 1.5611\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6385 - mae: 0.6385 - val_loss: 1.5395 - val_mae: 1.5395\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6334 - mae: 0.6334 - val_loss: 1.5261 - val_mae: 1.5261\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6307 - mae: 0.6307 - val_loss: 1.5176 - val_mae: 1.5176\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.9749 - mae: 1.9749 - val_loss: 0.4016 - val_mae: 0.4016\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7630 - mae: 0.7630 - val_loss: 0.5327 - val_mae: 0.5327\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6866 - mae: 0.6866 - val_loss: 0.3796 - val_mae: 0.3796\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6619 - mae: 0.6619 - val_loss: 0.3851 - val_mae: 0.3851\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6465 - mae: 0.6465 - val_loss: 0.4275 - val_mae: 0.4275\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6289 - mae: 0.6289 - val_loss: 0.3870 - val_mae: 0.3870\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6359 - mae: 0.6359 - val_loss: 0.3855 - val_mae: 0.3855\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6316 - mae: 0.6316 - val_loss: 0.5197 - val_mae: 0.5197\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6172 - mae: 0.6172 - val_loss: 0.3494 - val_mae: 0.3494\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6127 - mae: 0.6127 - val_loss: 0.4046 - val_mae: 0.4046\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6024 - mae: 0.6024 - val_loss: 0.4485 - val_mae: 0.4485\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5964 - mae: 0.5964 - val_loss: 0.3498 - val_mae: 0.3498\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5871 - mae: 0.5871 - val_loss: 0.3964 - val_mae: 0.3964\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5856 - mae: 0.5856 - val_loss: 0.3278 - val_mae: 0.3278\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5796 - mae: 0.5796 - val_loss: 0.3849 - val_mae: 0.3849\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5751 - mae: 0.5751 - val_loss: 0.3973 - val_mae: 0.3973\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5583 - mae: 0.5583 - val_loss: 0.4096 - val_mae: 0.4096\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5609 - mae: 0.5609 - val_loss: 0.3478 - val_mae: 0.3478\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5647 - mae: 0.5647 - val_loss: 0.4243 - val_mae: 0.4243\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5447 - mae: 0.5447 - val_loss: 0.3500 - val_mae: 0.3500\n",
            "\n",
            "\n",
            " FOLD\n",
            " 5 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 7ms/step - loss: 4.0897 - mae: 4.0897 - val_loss: 4.0229 - val_mae: 4.0229\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.4386 - mae: 3.4386 - val_loss: 3.1950 - val_mae: 3.1950\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.1667 - mae: 2.1667 - val_loss: 2.5066 - val_mae: 2.5066\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.3870 - mae: 1.3870 - val_loss: 1.8174 - val_mae: 1.8174\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7855 - mae: 0.7855 - val_loss: 1.6867 - val_mae: 1.6867\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7000 - mae: 0.7000 - val_loss: 1.6425 - val_mae: 1.6425\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6782 - mae: 0.6782 - val_loss: 1.6395 - val_mae: 1.6395\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6679 - mae: 0.6679 - val_loss: 1.6425 - val_mae: 1.6425\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6625 - mae: 0.6625 - val_loss: 1.6310 - val_mae: 1.6310\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6564 - mae: 0.6564 - val_loss: 1.6009 - val_mae: 1.6009\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6513 - mae: 0.6513 - val_loss: 1.6063 - val_mae: 1.6063\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6486 - mae: 0.6486 - val_loss: 1.6304 - val_mae: 1.6304\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6460 - mae: 0.6460 - val_loss: 1.5797 - val_mae: 1.5797\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6417 - mae: 0.6417 - val_loss: 1.5772 - val_mae: 1.5772\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6362 - mae: 0.6362 - val_loss: 1.5756 - val_mae: 1.5756\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.4034 - mae: 1.4034 - val_loss: 0.4137 - val_mae: 0.4137\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7485 - mae: 0.7485 - val_loss: 0.4955 - val_mae: 0.4955\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6744 - mae: 0.6744 - val_loss: 0.4746 - val_mae: 0.4746\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6517 - mae: 0.6517 - val_loss: 0.4511 - val_mae: 0.4511\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6509 - mae: 0.6509 - val_loss: 0.5426 - val_mae: 0.5426\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6205 - mae: 0.6205 - val_loss: 0.4761 - val_mae: 0.4761\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6252 - mae: 0.6252 - val_loss: 0.5458 - val_mae: 0.5458\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6065 - mae: 0.6065 - val_loss: 0.4627 - val_mae: 0.4627\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6099 - mae: 0.6099 - val_loss: 0.5851 - val_mae: 0.5851\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5991 - mae: 0.5991 - val_loss: 0.5959 - val_mae: 0.5959\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5817 - mae: 0.5817 - val_loss: 0.5563 - val_mae: 0.5563\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5792 - mae: 0.5792 - val_loss: 0.5417 - val_mae: 0.5417\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5804 - mae: 0.5804 - val_loss: 0.5381 - val_mae: 0.5381\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5603 - mae: 0.5603 - val_loss: 0.5832 - val_mae: 0.5832\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5672 - mae: 0.5672 - val_loss: 0.4858 - val_mae: 0.4858\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5647 - mae: 0.5647 - val_loss: 0.6604 - val_mae: 0.6604\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5596 - mae: 0.5596 - val_loss: 0.5925 - val_mae: 0.5925\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5540 - mae: 0.5540 - val_loss: 0.5497 - val_mae: 0.5497\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5552 - mae: 0.5552 - val_loss: 0.6359 - val_mae: 0.6359\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5282 - mae: 0.5282 - val_loss: 0.6137 - val_mae: 0.6137\n",
            "\n",
            " archi  [32, 16, 8] \n",
            "\n",
            "\n",
            "\n",
            " FOLD\n",
            " 1 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 3.8809 - mae: 3.8809 - val_loss: 3.4289 - val_mae: 3.4289\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.7274 - mae: 1.7274 - val_loss: 1.6606 - val_mae: 1.6606\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.8361 - mae: 0.8361 - val_loss: 1.3806 - val_mae: 1.3806\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7240 - mae: 0.7240 - val_loss: 1.3425 - val_mae: 1.3425\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6955 - mae: 0.6955 - val_loss: 1.3573 - val_mae: 1.3573\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6778 - mae: 0.6778 - val_loss: 1.3314 - val_mae: 1.3314\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6689 - mae: 0.6689 - val_loss: 1.3074 - val_mae: 1.3074\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6629 - mae: 0.6629 - val_loss: 1.2981 - val_mae: 1.2981\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6540 - mae: 0.6540 - val_loss: 1.2741 - val_mae: 1.2741\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6509 - mae: 0.6509 - val_loss: 1.2571 - val_mae: 1.2571\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6427 - mae: 0.6427 - val_loss: 1.2314 - val_mae: 1.2314\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6381 - mae: 0.6381 - val_loss: 1.2376 - val_mae: 1.2376\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6292 - mae: 0.6292 - val_loss: 1.2062 - val_mae: 1.2062\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6208 - mae: 0.6208 - val_loss: 1.1862 - val_mae: 1.1862\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6100 - mae: 0.6100 - val_loss: 1.1670 - val_mae: 1.1670\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 7ms/step - loss: 1.1311 - mae: 1.1311 - val_loss: 0.4542 - val_mae: 0.4542\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7307 - mae: 0.7307 - val_loss: 0.3908 - val_mae: 0.3908\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 1s 6ms/step - loss: 0.6779 - mae: 0.6779 - val_loss: 0.3389 - val_mae: 0.3389\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6458 - mae: 0.6458 - val_loss: 0.4007 - val_mae: 0.4007\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6384 - mae: 0.6384 - val_loss: 0.4592 - val_mae: 0.4592\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6235 - mae: 0.6235 - val_loss: 0.3635 - val_mae: 0.3635\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6064 - mae: 0.6064 - val_loss: 0.4422 - val_mae: 0.4422\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6187 - mae: 0.6187 - val_loss: 0.4437 - val_mae: 0.4437\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5943 - mae: 0.5943 - val_loss: 0.3823 - val_mae: 0.3823\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5898 - mae: 0.5898 - val_loss: 0.3679 - val_mae: 0.3679\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5963 - mae: 0.5963 - val_loss: 0.3730 - val_mae: 0.3730\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5901 - mae: 0.5901 - val_loss: 0.3500 - val_mae: 0.3500\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5890 - mae: 0.5890 - val_loss: 0.3238 - val_mae: 0.3238\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5801 - mae: 0.5801 - val_loss: 0.3399 - val_mae: 0.3399\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5745 - mae: 0.5745 - val_loss: 0.4331 - val_mae: 0.4331\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5565 - mae: 0.5565 - val_loss: 0.3800 - val_mae: 0.3800\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5626 - mae: 0.5626 - val_loss: 0.4548 - val_mae: 0.4548\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5548 - mae: 0.5548 - val_loss: 0.3513 - val_mae: 0.3513\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5385 - mae: 0.5385 - val_loss: 0.3317 - val_mae: 0.3317\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5465 - mae: 0.5465 - val_loss: 0.3535 - val_mae: 0.3535\n",
            "\n",
            "\n",
            " FOLD\n",
            " 2 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 7ms/step - loss: 4.0165 - mae: 4.0165 - val_loss: 3.8464 - val_mae: 3.8464\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.5882 - mae: 2.5882 - val_loss: 2.2280 - val_mae: 2.2280\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.4886 - mae: 1.4886 - val_loss: 1.8684 - val_mae: 1.8684\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.0573 - mae: 1.0573 - val_loss: 1.6332 - val_mae: 1.6332\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.8037 - mae: 0.8037 - val_loss: 1.4804 - val_mae: 1.4804\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7127 - mae: 0.7127 - val_loss: 1.4636 - val_mae: 1.4636\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6924 - mae: 0.6924 - val_loss: 1.4802 - val_mae: 1.4802\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6838 - mae: 0.6838 - val_loss: 1.4301 - val_mae: 1.4301\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6734 - mae: 0.6734 - val_loss: 1.4280 - val_mae: 1.4280\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6684 - mae: 0.6684 - val_loss: 1.4483 - val_mae: 1.4483\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6586 - mae: 0.6586 - val_loss: 1.4236 - val_mae: 1.4236\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6544 - mae: 0.6544 - val_loss: 1.4148 - val_mae: 1.4148\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6502 - mae: 0.6502 - val_loss: 1.3929 - val_mae: 1.3929\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6458 - mae: 0.6458 - val_loss: 1.3823 - val_mae: 1.3823\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6422 - mae: 0.6422 - val_loss: 1.3543 - val_mae: 1.3543\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.0144 - mae: 1.0144 - val_loss: 0.4145 - val_mae: 0.4145\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7072 - mae: 0.7072 - val_loss: 0.4597 - val_mae: 0.4597\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6407 - mae: 0.6407 - val_loss: 0.5237 - val_mae: 0.5237\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6286 - mae: 0.6286 - val_loss: 0.4829 - val_mae: 0.4829\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6292 - mae: 0.6292 - val_loss: 0.5028 - val_mae: 0.5028\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6251 - mae: 0.6251 - val_loss: 0.4338 - val_mae: 0.4338\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6076 - mae: 0.6076 - val_loss: 0.4195 - val_mae: 0.4195\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6018 - mae: 0.6018 - val_loss: 0.4245 - val_mae: 0.4245\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5894 - mae: 0.5894 - val_loss: 0.4545 - val_mae: 0.4545\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5871 - mae: 0.5871 - val_loss: 0.4177 - val_mae: 0.4177\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5868 - mae: 0.5868 - val_loss: 0.4166 - val_mae: 0.4166\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5846 - mae: 0.5846 - val_loss: 0.5328 - val_mae: 0.5328\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5754 - mae: 0.5754 - val_loss: 0.3788 - val_mae: 0.3788\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5628 - mae: 0.5628 - val_loss: 0.4597 - val_mae: 0.4597\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5626 - mae: 0.5626 - val_loss: 0.4253 - val_mae: 0.4253\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5586 - mae: 0.5586 - val_loss: 0.5294 - val_mae: 0.5294\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5552 - mae: 0.5552 - val_loss: 0.4405 - val_mae: 0.4405\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5519 - mae: 0.5519 - val_loss: 0.4068 - val_mae: 0.4068\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5381 - mae: 0.5381 - val_loss: 0.4158 - val_mae: 0.4158\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5334 - mae: 0.5334 - val_loss: 0.4088 - val_mae: 0.4088\n",
            "\n",
            "\n",
            " FOLD\n",
            " 3 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 4.0466 - mae: 4.0466 - val_loss: 3.9195 - val_mae: 3.9195\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.5392 - mae: 2.5392 - val_loss: 1.7427 - val_mae: 1.7427\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.9947 - mae: 0.9947 - val_loss: 1.6522 - val_mae: 1.6522\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7550 - mae: 0.7550 - val_loss: 1.5099 - val_mae: 1.5099\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.7102 - mae: 0.7102 - val_loss: 1.4872 - val_mae: 1.4872\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6909 - mae: 0.6909 - val_loss: 1.4966 - val_mae: 1.4966\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6837 - mae: 0.6837 - val_loss: 1.5132 - val_mae: 1.5132\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6772 - mae: 0.6772 - val_loss: 1.4604 - val_mae: 1.4604\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6716 - mae: 0.6716 - val_loss: 1.4643 - val_mae: 1.4643\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6677 - mae: 0.6677 - val_loss: 1.4716 - val_mae: 1.4716\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6653 - mae: 0.6653 - val_loss: 1.4798 - val_mae: 1.4798\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.4703 - mae: 1.4703 - val_loss: 0.5304 - val_mae: 0.5304\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7867 - mae: 0.7867 - val_loss: 0.4268 - val_mae: 0.4268\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7095 - mae: 0.7095 - val_loss: 0.4359 - val_mae: 0.4359\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6815 - mae: 0.6815 - val_loss: 0.4623 - val_mae: 0.4623\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6703 - mae: 0.6703 - val_loss: 0.4232 - val_mae: 0.4232\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6513 - mae: 0.6513 - val_loss: 0.3968 - val_mae: 0.3968\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6273 - mae: 0.6273 - val_loss: 0.3987 - val_mae: 0.3987\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6299 - mae: 0.6299 - val_loss: 0.5447 - val_mae: 0.5447\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6246 - mae: 0.6246 - val_loss: 0.3791 - val_mae: 0.3791\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6165 - mae: 0.6165 - val_loss: 0.3965 - val_mae: 0.3965\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6086 - mae: 0.6086 - val_loss: 0.4321 - val_mae: 0.4321\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6119 - mae: 0.6119 - val_loss: 0.4909 - val_mae: 0.4909\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6056 - mae: 0.6056 - val_loss: 0.4014 - val_mae: 0.4014\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5944 - mae: 0.5944 - val_loss: 0.4858 - val_mae: 0.4858\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5880 - mae: 0.5880 - val_loss: 0.3834 - val_mae: 0.3834\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5841 - mae: 0.5841 - val_loss: 0.3583 - val_mae: 0.3583\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5759 - mae: 0.5759 - val_loss: 0.3728 - val_mae: 0.3728\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5845 - mae: 0.5845 - val_loss: 0.4680 - val_mae: 0.4680\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5695 - mae: 0.5695 - val_loss: 0.3941 - val_mae: 0.3941\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5526 - mae: 0.5526 - val_loss: 0.4591 - val_mae: 0.4591\n",
            "\n",
            "\n",
            " FOLD\n",
            " 4 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 4.1051 - mae: 4.1051 - val_loss: 4.0396 - val_mae: 4.0396\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2244 - mae: 3.2244 - val_loss: 2.5389 - val_mae: 2.5389\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.8384 - mae: 1.8384 - val_loss: 2.1883 - val_mae: 2.1883\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.4860 - mae: 1.4860 - val_loss: 1.9430 - val_mae: 1.9430\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.1888 - mae: 1.1888 - val_loss: 1.6791 - val_mae: 1.6791\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.8849 - mae: 0.8849 - val_loss: 1.4611 - val_mae: 1.4611\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7190 - mae: 0.7190 - val_loss: 1.4529 - val_mae: 1.4529\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6908 - mae: 0.6908 - val_loss: 1.4042 - val_mae: 1.4042\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6820 - mae: 0.6820 - val_loss: 1.4154 - val_mae: 1.4154\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6738 - mae: 0.6738 - val_loss: 1.4057 - val_mae: 1.4057\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6689 - mae: 0.6689 - val_loss: 1.3965 - val_mae: 1.3965\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6665 - mae: 0.6665 - val_loss: 1.3766 - val_mae: 1.3766\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6601 - mae: 0.6601 - val_loss: 1.3675 - val_mae: 1.3675\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6588 - mae: 0.6588 - val_loss: 1.3586 - val_mae: 1.3586\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6547 - mae: 0.6547 - val_loss: 1.3652 - val_mae: 1.3652\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 8ms/step - loss: 1.3196 - mae: 1.3196 - val_loss: 0.5116 - val_mae: 0.5116\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7489 - mae: 0.7489 - val_loss: 0.4819 - val_mae: 0.4819\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6869 - mae: 0.6869 - val_loss: 0.4364 - val_mae: 0.4364\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6673 - mae: 0.6673 - val_loss: 0.4076 - val_mae: 0.4076\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6448 - mae: 0.6448 - val_loss: 0.4837 - val_mae: 0.4837\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6454 - mae: 0.6454 - val_loss: 0.4284 - val_mae: 0.4284\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6345 - mae: 0.6345 - val_loss: 0.4496 - val_mae: 0.4496\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6302 - mae: 0.6302 - val_loss: 0.3809 - val_mae: 0.3809\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6134 - mae: 0.6134 - val_loss: 0.3951 - val_mae: 0.3951\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6178 - mae: 0.6178 - val_loss: 0.4011 - val_mae: 0.4011\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6027 - mae: 0.6027 - val_loss: 0.4330 - val_mae: 0.4330\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6073 - mae: 0.6073 - val_loss: 0.4083 - val_mae: 0.4083\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6008 - mae: 0.6008 - val_loss: 0.3445 - val_mae: 0.3445\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5965 - mae: 0.5965 - val_loss: 0.4124 - val_mae: 0.4124\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5840 - mae: 0.5840 - val_loss: 0.4365 - val_mae: 0.4365\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5873 - mae: 0.5873 - val_loss: 0.3939 - val_mae: 0.3939\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5798 - mae: 0.5798 - val_loss: 0.3500 - val_mae: 0.3500\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5720 - mae: 0.5720 - val_loss: 0.3434 - val_mae: 0.3434\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5652 - mae: 0.5652 - val_loss: 0.3805 - val_mae: 0.3805\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5637 - mae: 0.5637 - val_loss: 0.3582 - val_mae: 0.3582\n",
            "\n",
            "\n",
            " FOLD\n",
            " 5 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 4.0490 - mae: 4.0490 - val_loss: 3.8508 - val_mae: 3.8508\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.4026 - mae: 2.4026 - val_loss: 1.8263 - val_mae: 1.8263\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.9370 - mae: 0.9370 - val_loss: 1.4828 - val_mae: 1.4828\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7306 - mae: 0.7306 - val_loss: 1.4422 - val_mae: 1.4422\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6973 - mae: 0.6973 - val_loss: 1.4141 - val_mae: 1.4141\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6784 - mae: 0.6784 - val_loss: 1.4099 - val_mae: 1.4099\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6671 - mae: 0.6671 - val_loss: 1.3907 - val_mae: 1.3907\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6578 - mae: 0.6578 - val_loss: 1.3905 - val_mae: 1.3905\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6512 - mae: 0.6512 - val_loss: 1.3579 - val_mae: 1.3579\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6437 - mae: 0.6437 - val_loss: 1.3311 - val_mae: 1.3311\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6395 - mae: 0.6395 - val_loss: 1.3629 - val_mae: 1.3629\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6346 - mae: 0.6346 - val_loss: 1.3237 - val_mae: 1.3237\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6269 - mae: 0.6269 - val_loss: 1.3342 - val_mae: 1.3342\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6237 - mae: 0.6237 - val_loss: 1.3241 - val_mae: 1.3241\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6200 - mae: 0.6200 - val_loss: 1.3067 - val_mae: 1.3067\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.3086 - mae: 1.3086 - val_loss: 0.4119 - val_mae: 0.4119\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7654 - mae: 0.7654 - val_loss: 0.4192 - val_mae: 0.4192\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6843 - mae: 0.6843 - val_loss: 0.5538 - val_mae: 0.5538\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6558 - mae: 0.6558 - val_loss: 0.5219 - val_mae: 0.5219\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6325 - mae: 0.6325 - val_loss: 0.4436 - val_mae: 0.4436\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6185 - mae: 0.6185 - val_loss: 0.4688 - val_mae: 0.4688\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6108 - mae: 0.6108 - val_loss: 0.4229 - val_mae: 0.4229\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6027 - mae: 0.6027 - val_loss: 0.4343 - val_mae: 0.4343\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5954 - mae: 0.5954 - val_loss: 0.4146 - val_mae: 0.4146\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5868 - mae: 0.5868 - val_loss: 0.4991 - val_mae: 0.4991\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5854 - mae: 0.5854 - val_loss: 0.4203 - val_mae: 0.4203\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5746 - mae: 0.5746 - val_loss: 0.5023 - val_mae: 0.5023\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5652 - mae: 0.5652 - val_loss: 0.4190 - val_mae: 0.4190\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5791 - mae: 0.5791 - val_loss: 0.4222 - val_mae: 0.4222\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5639 - mae: 0.5639 - val_loss: 0.4851 - val_mae: 0.4851\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5521 - mae: 0.5521 - val_loss: 0.4910 - val_mae: 0.4910\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5583 - mae: 0.5583 - val_loss: 0.4585 - val_mae: 0.4585\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5531 - mae: 0.5531 - val_loss: 0.4303 - val_mae: 0.4303\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5448 - mae: 0.5448 - val_loss: 0.3735 - val_mae: 0.3735\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5428 - mae: 0.5428 - val_loss: 0.4220 - val_mae: 0.4220\n",
            "\n",
            " archi  [64, 32, 16, 8] \n",
            "\n",
            "\n",
            "\n",
            " FOLD\n",
            " 1 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 10ms/step - loss: 4.0823 - mae: 4.0823 - val_loss: 3.9266 - val_mae: 3.9266\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.8590 - mae: 2.8590 - val_loss: 2.5811 - val_mae: 2.5811\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.9961 - mae: 1.9961 - val_loss: 1.9502 - val_mae: 1.9502\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.2847 - mae: 1.2847 - val_loss: 1.5305 - val_mae: 1.5305\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.8932 - mae: 0.8932 - val_loss: 1.2847 - val_mae: 1.2847\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6995 - mae: 0.6995 - val_loss: 1.2047 - val_mae: 1.2047\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6774 - mae: 0.6774 - val_loss: 1.2001 - val_mae: 1.2001\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6674 - mae: 0.6674 - val_loss: 1.1298 - val_mae: 1.1298\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6597 - mae: 0.6597 - val_loss: 1.2014 - val_mae: 1.2014\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6522 - mae: 0.6522 - val_loss: 1.1239 - val_mae: 1.1239\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6478 - mae: 0.6478 - val_loss: 1.1164 - val_mae: 1.1164\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6407 - mae: 0.6407 - val_loss: 1.0867 - val_mae: 1.0867\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6396 - mae: 0.6396 - val_loss: 1.1294 - val_mae: 1.1294\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6321 - mae: 0.6321 - val_loss: 1.0820 - val_mae: 1.0820\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6234 - mae: 0.6234 - val_loss: 1.0448 - val_mae: 1.0448\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.0302 - mae: 1.0302 - val_loss: 0.5059 - val_mae: 0.5059\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6830 - mae: 0.6830 - val_loss: 0.4944 - val_mae: 0.4944\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6450 - mae: 0.6450 - val_loss: 0.5212 - val_mae: 0.5212\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6206 - mae: 0.6206 - val_loss: 0.4888 - val_mae: 0.4888\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6104 - mae: 0.6104 - val_loss: 0.4731 - val_mae: 0.4731\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5937 - mae: 0.5937 - val_loss: 0.5643 - val_mae: 0.5643\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5942 - mae: 0.5942 - val_loss: 0.5170 - val_mae: 0.5170\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5820 - mae: 0.5820 - val_loss: 0.5470 - val_mae: 0.5470\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5806 - mae: 0.5806 - val_loss: 0.6808 - val_mae: 0.6808\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5806 - mae: 0.5806 - val_loss: 0.6417 - val_mae: 0.6417\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5698 - mae: 0.5698 - val_loss: 0.4707 - val_mae: 0.4707\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5664 - mae: 0.5664 - val_loss: 0.7031 - val_mae: 0.7031\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5569 - mae: 0.5569 - val_loss: 0.5916 - val_mae: 0.5916\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5537 - mae: 0.5537 - val_loss: 0.5473 - val_mae: 0.5473\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5446 - mae: 0.5446 - val_loss: 0.5672 - val_mae: 0.5672\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5427 - mae: 0.5427 - val_loss: 0.5672 - val_mae: 0.5672\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5416 - mae: 0.5416 - val_loss: 0.5075 - val_mae: 0.5075\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5358 - mae: 0.5358 - val_loss: 0.6160 - val_mae: 0.6160\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5273 - mae: 0.5273 - val_loss: 0.6742 - val_mae: 0.6742\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5283 - mae: 0.5283 - val_loss: 0.6297 - val_mae: 0.6297\n",
            "\n",
            "\n",
            " FOLD\n",
            " 2 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 3.7638 - mae: 3.7638 - val_loss: 2.8634 - val_mae: 2.8634\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.3243 - mae: 1.3243 - val_loss: 1.3152 - val_mae: 1.3152\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.8459 - mae: 0.8459 - val_loss: 1.2251 - val_mae: 1.2251\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.7287 - mae: 0.7287 - val_loss: 1.1941 - val_mae: 1.1941\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6986 - mae: 0.6986 - val_loss: 1.1890 - val_mae: 1.1890\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6827 - mae: 0.6827 - val_loss: 1.1493 - val_mae: 1.1493\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6717 - mae: 0.6717 - val_loss: 1.1651 - val_mae: 1.1651\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6636 - mae: 0.6636 - val_loss: 1.1376 - val_mae: 1.1376\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6565 - mae: 0.6565 - val_loss: 1.1118 - val_mae: 1.1118\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6495 - mae: 0.6495 - val_loss: 1.0631 - val_mae: 1.0631\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6438 - mae: 0.6438 - val_loss: 1.0289 - val_mae: 1.0289\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6359 - mae: 0.6359 - val_loss: 1.0431 - val_mae: 1.0431\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6267 - mae: 0.6267 - val_loss: 1.0280 - val_mae: 1.0280\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6153 - mae: 0.6153 - val_loss: 0.9944 - val_mae: 0.9944\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.5959 - mae: 0.5959 - val_loss: 0.9920 - val_mae: 0.9920\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.0955 - mae: 1.0955 - val_loss: 0.4294 - val_mae: 0.4294\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7028 - mae: 0.7028 - val_loss: 0.5068 - val_mae: 0.5068\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6420 - mae: 0.6420 - val_loss: 0.6323 - val_mae: 0.6323\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6198 - mae: 0.6198 - val_loss: 0.4315 - val_mae: 0.4315\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6043 - mae: 0.6043 - val_loss: 0.3572 - val_mae: 0.3572\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5986 - mae: 0.5986 - val_loss: 0.4224 - val_mae: 0.4224\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5977 - mae: 0.5977 - val_loss: 0.4294 - val_mae: 0.4294\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5913 - mae: 0.5913 - val_loss: 0.4809 - val_mae: 0.4809\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5809 - mae: 0.5809 - val_loss: 0.5034 - val_mae: 0.5034\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5860 - mae: 0.5860 - val_loss: 0.4969 - val_mae: 0.4969\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5761 - mae: 0.5761 - val_loss: 0.4279 - val_mae: 0.4279\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5679 - mae: 0.5679 - val_loss: 0.3582 - val_mae: 0.3582\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5536 - mae: 0.5536 - val_loss: 0.4510 - val_mae: 0.4510\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5539 - mae: 0.5539 - val_loss: 0.4076 - val_mae: 0.4076\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5555 - mae: 0.5555 - val_loss: 0.4627 - val_mae: 0.4627\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5606 - mae: 0.5606 - val_loss: 0.4360 - val_mae: 0.4360\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5482 - mae: 0.5482 - val_loss: 0.4099 - val_mae: 0.4099\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5395 - mae: 0.5395 - val_loss: 0.3717 - val_mae: 0.3717\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5410 - mae: 0.5410 - val_loss: 0.4417 - val_mae: 0.4417\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5298 - mae: 0.5298 - val_loss: 0.3941 - val_mae: 0.3941\n",
            "\n",
            "\n",
            " FOLD\n",
            " 3 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 3.8381 - mae: 3.8381 - val_loss: 3.0619 - val_mae: 3.0619\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.0605 - mae: 2.0605 - val_loss: 1.8947 - val_mae: 1.8947\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.1306 - mae: 1.1306 - val_loss: 1.2547 - val_mae: 1.2547\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.7464 - mae: 0.7464 - val_loss: 1.1457 - val_mae: 1.1457\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6959 - mae: 0.6959 - val_loss: 1.1643 - val_mae: 1.1643\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6744 - mae: 0.6744 - val_loss: 1.1032 - val_mae: 1.1032\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6624 - mae: 0.6624 - val_loss: 1.0759 - val_mae: 1.0759\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6511 - mae: 0.6511 - val_loss: 1.0712 - val_mae: 1.0712\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6371 - mae: 0.6371 - val_loss: 1.0478 - val_mae: 1.0478\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6258 - mae: 0.6258 - val_loss: 1.0123 - val_mae: 1.0123\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6100 - mae: 0.6100 - val_loss: 1.0434 - val_mae: 1.0434\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5941 - mae: 0.5941 - val_loss: 0.9935 - val_mae: 0.9935\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.5759 - mae: 0.5759 - val_loss: 1.0127 - val_mae: 1.0127\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5547 - mae: 0.5547 - val_loss: 0.9899 - val_mae: 0.9899\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5332 - mae: 0.5332 - val_loss: 1.0281 - val_mae: 1.0281\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.4527 - mae: 1.4527 - val_loss: 0.4480 - val_mae: 0.4480\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7396 - mae: 0.7396 - val_loss: 0.4824 - val_mae: 0.4824\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6598 - mae: 0.6598 - val_loss: 0.5145 - val_mae: 0.5145\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6321 - mae: 0.6321 - val_loss: 0.3332 - val_mae: 0.3332\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6252 - mae: 0.6252 - val_loss: 0.3702 - val_mae: 0.3702\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6213 - mae: 0.6213 - val_loss: 0.3244 - val_mae: 0.3244\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6062 - mae: 0.6062 - val_loss: 0.4731 - val_mae: 0.4731\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5934 - mae: 0.5934 - val_loss: 0.3422 - val_mae: 0.3422\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5894 - mae: 0.5894 - val_loss: 0.4429 - val_mae: 0.4429\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5896 - mae: 0.5896 - val_loss: 0.3790 - val_mae: 0.3790\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5833 - mae: 0.5833 - val_loss: 0.3631 - val_mae: 0.3631\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5768 - mae: 0.5768 - val_loss: 0.4345 - val_mae: 0.4345\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5659 - mae: 0.5659 - val_loss: 0.4690 - val_mae: 0.4690\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5705 - mae: 0.5705 - val_loss: 0.4204 - val_mae: 0.4204\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5622 - mae: 0.5622 - val_loss: 0.3721 - val_mae: 0.3721\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5531 - mae: 0.5531 - val_loss: 0.3472 - val_mae: 0.3472\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5604 - mae: 0.5604 - val_loss: 0.4395 - val_mae: 0.4395\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5607 - mae: 0.5607 - val_loss: 0.3820 - val_mae: 0.3820\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5428 - mae: 0.5428 - val_loss: 0.3273 - val_mae: 0.3273\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5380 - mae: 0.5380 - val_loss: 0.3544 - val_mae: 0.3544\n",
            "\n",
            "\n",
            " FOLD\n",
            " 4 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 3.9082 - mae: 3.9082 - val_loss: 3.3290 - val_mae: 3.3290\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.9202 - mae: 2.9202 - val_loss: 2.7154 - val_mae: 2.7154\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.2372 - mae: 2.2372 - val_loss: 2.0535 - val_mae: 2.0535\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.5123 - mae: 1.5123 - val_loss: 1.3300 - val_mae: 1.3300\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.8961 - mae: 0.8961 - val_loss: 1.0311 - val_mae: 1.0311\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6945 - mae: 0.6945 - val_loss: 0.9825 - val_mae: 0.9825\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6655 - mae: 0.6655 - val_loss: 0.9344 - val_mae: 0.9344\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6474 - mae: 0.6474 - val_loss: 0.9643 - val_mae: 0.9643\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6307 - mae: 0.6307 - val_loss: 0.9050 - val_mae: 0.9050\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6086 - mae: 0.6086 - val_loss: 0.9396 - val_mae: 0.9396\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5841 - mae: 0.5841 - val_loss: 0.9177 - val_mae: 0.9177\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5557 - mae: 0.5557 - val_loss: 0.9220 - val_mae: 0.9220\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.2347 - mae: 1.2347 - val_loss: 0.4805 - val_mae: 0.4805\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7411 - mae: 0.7411 - val_loss: 0.4120 - val_mae: 0.4120\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6954 - mae: 0.6954 - val_loss: 0.4002 - val_mae: 0.4002\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6652 - mae: 0.6652 - val_loss: 0.3804 - val_mae: 0.3804\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6541 - mae: 0.6541 - val_loss: 0.3504 - val_mae: 0.3504\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6461 - mae: 0.6461 - val_loss: 0.4144 - val_mae: 0.4144\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6398 - mae: 0.6398 - val_loss: 0.3588 - val_mae: 0.3588\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6275 - mae: 0.6275 - val_loss: 0.3780 - val_mae: 0.3780\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6274 - mae: 0.6274 - val_loss: 0.3903 - val_mae: 0.3903\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6138 - mae: 0.6138 - val_loss: 0.3644 - val_mae: 0.3644\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6003 - mae: 0.6003 - val_loss: 0.3671 - val_mae: 0.3671\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6104 - mae: 0.6104 - val_loss: 0.3886 - val_mae: 0.3886\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6010 - mae: 0.6010 - val_loss: 0.3616 - val_mae: 0.3616\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5951 - mae: 0.5951 - val_loss: 0.3915 - val_mae: 0.3915\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5882 - mae: 0.5882 - val_loss: 0.3719 - val_mae: 0.3719\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5829 - mae: 0.5829 - val_loss: 0.3749 - val_mae: 0.3749\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5801 - mae: 0.5801 - val_loss: 0.3634 - val_mae: 0.3634\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5726 - mae: 0.5726 - val_loss: 0.3677 - val_mae: 0.3677\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5659 - mae: 0.5659 - val_loss: 0.3649 - val_mae: 0.3649\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5594 - mae: 0.5594 - val_loss: 0.3756 - val_mae: 0.3756\n",
            "\n",
            "\n",
            " FOLD\n",
            " 5 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 8ms/step - loss: 3.8570 - mae: 3.8570 - val_loss: 3.1009 - val_mae: 3.1009\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.0719 - mae: 2.0719 - val_loss: 1.8570 - val_mae: 1.8570\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 1.1044 - mae: 1.1044 - val_loss: 1.2285 - val_mae: 1.2285\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.7413 - mae: 0.7413 - val_loss: 1.1531 - val_mae: 1.1531\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6997 - mae: 0.6997 - val_loss: 1.1407 - val_mae: 1.1407\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6762 - mae: 0.6762 - val_loss: 1.1103 - val_mae: 1.1103\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6640 - mae: 0.6640 - val_loss: 1.0760 - val_mae: 1.0760\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6546 - mae: 0.6546 - val_loss: 1.1011 - val_mae: 1.1011\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6465 - mae: 0.6465 - val_loss: 1.0419 - val_mae: 1.0419\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6367 - mae: 0.6367 - val_loss: 1.0293 - val_mae: 1.0293\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6311 - mae: 0.6311 - val_loss: 0.9912 - val_mae: 0.9912\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6194 - mae: 0.6194 - val_loss: 1.0134 - val_mae: 1.0134\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6046 - mae: 0.6046 - val_loss: 0.9976 - val_mae: 0.9976\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5911 - mae: 0.5911 - val_loss: 0.9818 - val_mae: 0.9818\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.5745 - mae: 0.5745 - val_loss: 0.9846 - val_mae: 0.9846\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 0.9784 - mae: 0.9784 - val_loss: 0.6002 - val_mae: 0.6002\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7384 - mae: 0.7384 - val_loss: 0.4274 - val_mae: 0.4274\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6765 - mae: 0.6765 - val_loss: 0.4844 - val_mae: 0.4844\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6408 - mae: 0.6408 - val_loss: 0.4549 - val_mae: 0.4549\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6191 - mae: 0.6191 - val_loss: 0.5262 - val_mae: 0.5262\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6045 - mae: 0.6045 - val_loss: 0.4639 - val_mae: 0.4639\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5890 - mae: 0.5890 - val_loss: 0.5464 - val_mae: 0.5464\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5854 - mae: 0.5854 - val_loss: 0.4289 - val_mae: 0.4289\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5877 - mae: 0.5877 - val_loss: 0.4241 - val_mae: 0.4241\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5818 - mae: 0.5818 - val_loss: 0.5312 - val_mae: 0.5312\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5624 - mae: 0.5624 - val_loss: 0.4887 - val_mae: 0.4887\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5517 - mae: 0.5517 - val_loss: 0.5096 - val_mae: 0.5096\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5427 - mae: 0.5427 - val_loss: 0.4936 - val_mae: 0.4936\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5430 - mae: 0.5430 - val_loss: 0.4803 - val_mae: 0.4803\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5361 - mae: 0.5361 - val_loss: 0.5303 - val_mae: 0.5303\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5367 - mae: 0.5367 - val_loss: 0.6018 - val_mae: 0.6018\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5316 - mae: 0.5316 - val_loss: 0.5065 - val_mae: 0.5065\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5230 - mae: 0.5230 - val_loss: 0.5214 - val_mae: 0.5214\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5217 - mae: 0.5217 - val_loss: 0.5284 - val_mae: 0.5284\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5069 - mae: 0.5069 - val_loss: 0.4943 - val_mae: 0.4943\n",
            "\n",
            " archi  [128, 64, 32, 16, 8] \n",
            "\n",
            "\n",
            "\n",
            " FOLD\n",
            " 1 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 3.3366 - mae: 3.3366 - val_loss: 1.7581 - val_mae: 1.7581\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.0302 - mae: 1.0302 - val_loss: 0.9463 - val_mae: 0.9463\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.7271 - mae: 0.7271 - val_loss: 0.9410 - val_mae: 0.9410\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6862 - mae: 0.6862 - val_loss: 0.9216 - val_mae: 0.9216\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6729 - mae: 0.6729 - val_loss: 0.9514 - val_mae: 0.9514\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6547 - mae: 0.6547 - val_loss: 0.9380 - val_mae: 0.9380\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6450 - mae: 0.6450 - val_loss: 0.9361 - val_mae: 0.9361\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.9467 - mae: 0.9467 - val_loss: 0.4224 - val_mae: 0.4224\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6802 - mae: 0.6802 - val_loss: 0.5433 - val_mae: 0.5433\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6243 - mae: 0.6243 - val_loss: 0.6546 - val_mae: 0.6546\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6118 - mae: 0.6118 - val_loss: 0.5743 - val_mae: 0.5743\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5953 - mae: 0.5953 - val_loss: 0.5505 - val_mae: 0.5505\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5932 - mae: 0.5932 - val_loss: 0.5551 - val_mae: 0.5551\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5906 - mae: 0.5906 - val_loss: 0.4876 - val_mae: 0.4876\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5888 - mae: 0.5888 - val_loss: 0.6136 - val_mae: 0.6136\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5810 - mae: 0.5810 - val_loss: 0.5021 - val_mae: 0.5021\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5804 - mae: 0.5804 - val_loss: 0.5361 - val_mae: 0.5361\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5666 - mae: 0.5666 - val_loss: 0.5456 - val_mae: 0.5456\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5667 - mae: 0.5667 - val_loss: 0.5656 - val_mae: 0.5656\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5620 - mae: 0.5620 - val_loss: 0.5719 - val_mae: 0.5719\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5553 - mae: 0.5553 - val_loss: 0.6617 - val_mae: 0.6617\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5580 - mae: 0.5580 - val_loss: 0.5628 - val_mae: 0.5628\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5506 - mae: 0.5506 - val_loss: 0.5698 - val_mae: 0.5698\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5377 - mae: 0.5377 - val_loss: 0.5492 - val_mae: 0.5492\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5310 - mae: 0.5310 - val_loss: 0.4977 - val_mae: 0.4977\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5279 - mae: 0.5279 - val_loss: 0.5425 - val_mae: 0.5425\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5308 - mae: 0.5308 - val_loss: 0.5722 - val_mae: 0.5722\n",
            "\n",
            "\n",
            " FOLD\n",
            " 2 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 3.4019 - mae: 3.4019 - val_loss: 2.3396 - val_mae: 2.3396\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.7090 - mae: 1.7090 - val_loss: 1.4181 - val_mae: 1.4181\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 1.0380 - mae: 1.0380 - val_loss: 1.0270 - val_mae: 1.0270\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.7263 - mae: 0.7263 - val_loss: 0.9265 - val_mae: 0.9265\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6801 - mae: 0.6801 - val_loss: 0.8977 - val_mae: 0.8977\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6600 - mae: 0.6600 - val_loss: 0.8888 - val_mae: 0.8888\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6361 - mae: 0.6361 - val_loss: 0.8805 - val_mae: 0.8805\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6178 - mae: 0.6178 - val_loss: 0.8733 - val_mae: 0.8733\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.5911 - mae: 0.5911 - val_loss: 0.9184 - val_mae: 0.9184\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5662 - mae: 0.5662 - val_loss: 0.9331 - val_mae: 0.9331\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5429 - mae: 0.5429 - val_loss: 0.9408 - val_mae: 0.9408\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.6629 - mae: 1.6629 - val_loss: 0.5959 - val_mae: 0.5959\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7708 - mae: 0.7708 - val_loss: 0.5154 - val_mae: 0.5154\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6748 - mae: 0.6748 - val_loss: 0.4513 - val_mae: 0.4513\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6625 - mae: 0.6625 - val_loss: 0.3936 - val_mae: 0.3936\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6315 - mae: 0.6315 - val_loss: 0.4488 - val_mae: 0.4488\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6335 - mae: 0.6335 - val_loss: 0.3932 - val_mae: 0.3932\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6270 - mae: 0.6270 - val_loss: 0.4415 - val_mae: 0.4415\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6123 - mae: 0.6123 - val_loss: 0.4140 - val_mae: 0.4140\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6045 - mae: 0.6045 - val_loss: 0.3914 - val_mae: 0.3914\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6031 - mae: 0.6031 - val_loss: 0.4556 - val_mae: 0.4556\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5911 - mae: 0.5911 - val_loss: 0.3628 - val_mae: 0.3628\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5815 - mae: 0.5815 - val_loss: 0.4560 - val_mae: 0.4560\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5858 - mae: 0.5858 - val_loss: 0.3944 - val_mae: 0.3944\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5673 - mae: 0.5673 - val_loss: 0.4014 - val_mae: 0.4014\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5810 - mae: 0.5810 - val_loss: 0.4353 - val_mae: 0.4353\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5537 - mae: 0.5537 - val_loss: 0.4847 - val_mae: 0.4847\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5656 - mae: 0.5656 - val_loss: 0.4050 - val_mae: 0.4050\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5559 - mae: 0.5559 - val_loss: 0.3824 - val_mae: 0.3824\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5528 - mae: 0.5528 - val_loss: 0.4031 - val_mae: 0.4031\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5408 - mae: 0.5408 - val_loss: 0.3966 - val_mae: 0.3966\n",
            "\n",
            "\n",
            " FOLD\n",
            " 3 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 3.8417 - mae: 3.8417 - val_loss: 3.1190 - val_mae: 3.1190\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.4819 - mae: 2.4819 - val_loss: 2.0716 - val_mae: 2.0716\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.2031 - mae: 1.2031 - val_loss: 0.9759 - val_mae: 0.9759\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.7198 - mae: 0.7198 - val_loss: 0.9197 - val_mae: 0.9197\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6849 - mae: 0.6849 - val_loss: 0.9457 - val_mae: 0.9457\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6720 - mae: 0.6720 - val_loss: 0.9222 - val_mae: 0.9222\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6608 - mae: 0.6608 - val_loss: 0.9115 - val_mae: 0.9115\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6545 - mae: 0.6545 - val_loss: 0.8854 - val_mae: 0.8854\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6445 - mae: 0.6445 - val_loss: 0.8915 - val_mae: 0.8915\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6309 - mae: 0.6309 - val_loss: 0.8812 - val_mae: 0.8812\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6156 - mae: 0.6156 - val_loss: 0.8997 - val_mae: 0.8997\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.5957 - mae: 0.5957 - val_loss: 0.8933 - val_mae: 0.8933\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.5701 - mae: 0.5701 - val_loss: 0.9109 - val_mae: 0.9109\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 0.9042 - mae: 0.9042 - val_loss: 0.5806 - val_mae: 0.5806\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6832 - mae: 0.6832 - val_loss: 0.3840 - val_mae: 0.3840\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6263 - mae: 0.6263 - val_loss: 0.5354 - val_mae: 0.5354\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6030 - mae: 0.6030 - val_loss: 0.5419 - val_mae: 0.5419\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6023 - mae: 0.6023 - val_loss: 0.5124 - val_mae: 0.5124\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5933 - mae: 0.5933 - val_loss: 0.6532 - val_mae: 0.6532\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5877 - mae: 0.5877 - val_loss: 0.4244 - val_mae: 0.4244\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5765 - mae: 0.5765 - val_loss: 0.4554 - val_mae: 0.4554\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5717 - mae: 0.5717 - val_loss: 0.4665 - val_mae: 0.4665\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5670 - mae: 0.5670 - val_loss: 0.5578 - val_mae: 0.5578\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5676 - mae: 0.5676 - val_loss: 0.3869 - val_mae: 0.3869\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5636 - mae: 0.5636 - val_loss: 0.3963 - val_mae: 0.3963\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5545 - mae: 0.5545 - val_loss: 0.4404 - val_mae: 0.4404\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5478 - mae: 0.5478 - val_loss: 0.3984 - val_mae: 0.3984\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5483 - mae: 0.5483 - val_loss: 0.4057 - val_mae: 0.4057\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5414 - mae: 0.5414 - val_loss: 0.5130 - val_mae: 0.5130\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5337 - mae: 0.5337 - val_loss: 0.5841 - val_mae: 0.5841\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5363 - mae: 0.5363 - val_loss: 0.4581 - val_mae: 0.4581\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5257 - mae: 0.5257 - val_loss: 0.3997 - val_mae: 0.3997\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5206 - mae: 0.5206 - val_loss: 0.4440 - val_mae: 0.4440\n",
            "\n",
            "\n",
            " FOLD\n",
            " 4 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 10ms/step - loss: 4.0478 - mae: 4.0478 - val_loss: 3.8422 - val_mae: 3.8422\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.5536 - mae: 3.5536 - val_loss: 3.4642 - val_mae: 3.4642\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.1789 - mae: 3.1789 - val_loss: 3.1609 - val_mae: 3.1609\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.8604 - mae: 2.8604 - val_loss: 2.8576 - val_mae: 2.8576\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.5679 - mae: 2.5679 - val_loss: 2.6349 - val_mae: 2.6349\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.3051 - mae: 2.3051 - val_loss: 2.3636 - val_mae: 2.3636\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.0791 - mae: 2.0791 - val_loss: 2.1545 - val_mae: 2.1545\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.8579 - mae: 1.8579 - val_loss: 2.0031 - val_mae: 2.0031\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.6370 - mae: 1.6370 - val_loss: 1.8289 - val_mae: 1.8289\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 1.4178 - mae: 1.4178 - val_loss: 1.6228 - val_mae: 1.6228\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.1764 - mae: 1.1764 - val_loss: 1.4064 - val_mae: 1.4064\n",
            "Epoch 12/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.8889 - mae: 0.8889 - val_loss: 1.1525 - val_mae: 1.1525\n",
            "Epoch 13/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6013 - mae: 0.6013 - val_loss: 0.9672 - val_mae: 0.9672\n",
            "Epoch 14/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.5184 - mae: 0.5184 - val_loss: 0.9735 - val_mae: 0.9735\n",
            "Epoch 15/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.5057 - mae: 0.5057 - val_loss: 0.9838 - val_mae: 0.9838\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.3734 - mae: 1.3734 - val_loss: 0.6598 - val_mae: 0.6598\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7313 - mae: 0.7313 - val_loss: 0.4998 - val_mae: 0.4998\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6860 - mae: 0.6860 - val_loss: 0.5342 - val_mae: 0.5342\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6626 - mae: 0.6626 - val_loss: 0.5206 - val_mae: 0.5206\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6569 - mae: 0.6569 - val_loss: 0.5476 - val_mae: 0.5476\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6419 - mae: 0.6419 - val_loss: 0.5114 - val_mae: 0.5114\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6162 - mae: 0.6162 - val_loss: 0.4550 - val_mae: 0.4550\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6171 - mae: 0.6171 - val_loss: 0.5444 - val_mae: 0.5444\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6165 - mae: 0.6165 - val_loss: 0.4610 - val_mae: 0.4610\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5985 - mae: 0.5985 - val_loss: 0.4517 - val_mae: 0.4517\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6093 - mae: 0.6093 - val_loss: 0.4398 - val_mae: 0.4398\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5940 - mae: 0.5940 - val_loss: 0.5404 - val_mae: 0.5404\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5863 - mae: 0.5863 - val_loss: 0.4847 - val_mae: 0.4847\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5820 - mae: 0.5820 - val_loss: 0.4950 - val_mae: 0.4950\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.5786 - mae: 0.5786 - val_loss: 0.5192 - val_mae: 0.5192\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5721 - mae: 0.5721 - val_loss: 0.5617 - val_mae: 0.5617\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5657 - mae: 0.5657 - val_loss: 0.4686 - val_mae: 0.4686\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5497 - mae: 0.5497 - val_loss: 0.4984 - val_mae: 0.4984\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5479 - mae: 0.5479 - val_loss: 0.4612 - val_mae: 0.4612\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5450 - mae: 0.5450 - val_loss: 0.5005 - val_mae: 0.5005\n",
            "\n",
            "\n",
            " FOLD\n",
            " 5 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 3.6174 - mae: 3.6174 - val_loss: 2.1472 - val_mae: 2.1472\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.5660 - mae: 1.5660 - val_loss: 1.3634 - val_mae: 1.3634\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.9768 - mae: 0.9768 - val_loss: 1.0065 - val_mae: 1.0065\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.7119 - mae: 0.7119 - val_loss: 0.9195 - val_mae: 0.9195\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6788 - mae: 0.6788 - val_loss: 0.9192 - val_mae: 0.9192\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6576 - mae: 0.6576 - val_loss: 0.8951 - val_mae: 0.8951\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6455 - mae: 0.6455 - val_loss: 0.8929 - val_mae: 0.8929\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6293 - mae: 0.6293 - val_loss: 0.8713 - val_mae: 0.8713\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6145 - mae: 0.6145 - val_loss: 0.9086 - val_mae: 0.9086\n",
            "Epoch 10/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.5889 - mae: 0.5889 - val_loss: 0.9240 - val_mae: 0.9240\n",
            "Epoch 11/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5612 - mae: 0.5612 - val_loss: 0.9247 - val_mae: 0.9247\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.1300 - mae: 1.1300 - val_loss: 0.3831 - val_mae: 0.3831\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7079 - mae: 0.7079 - val_loss: 0.4433 - val_mae: 0.4433\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6489 - mae: 0.6489 - val_loss: 0.5205 - val_mae: 0.5205\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6230 - mae: 0.6230 - val_loss: 0.4803 - val_mae: 0.4803\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6089 - mae: 0.6089 - val_loss: 0.4886 - val_mae: 0.4886\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5984 - mae: 0.5984 - val_loss: 0.4131 - val_mae: 0.4131\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5931 - mae: 0.5931 - val_loss: 0.4884 - val_mae: 0.4884\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5876 - mae: 0.5876 - val_loss: 0.3386 - val_mae: 0.3386\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5782 - mae: 0.5782 - val_loss: 0.4059 - val_mae: 0.4059\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5791 - mae: 0.5791 - val_loss: 0.3850 - val_mae: 0.3850\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5722 - mae: 0.5722 - val_loss: 0.4296 - val_mae: 0.4296\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5625 - mae: 0.5625 - val_loss: 0.4181 - val_mae: 0.4181\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5641 - mae: 0.5641 - val_loss: 0.4507 - val_mae: 0.4507\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5595 - mae: 0.5595 - val_loss: 0.3991 - val_mae: 0.3991\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5517 - mae: 0.5517 - val_loss: 0.4160 - val_mae: 0.4160\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5519 - mae: 0.5519 - val_loss: 0.3923 - val_mae: 0.3923\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5476 - mae: 0.5476 - val_loss: 0.4103 - val_mae: 0.4103\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5416 - mae: 0.5416 - val_loss: 0.4341 - val_mae: 0.4341\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5477 - mae: 0.5477 - val_loss: 0.4172 - val_mae: 0.4172\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5407 - mae: 0.5407 - val_loss: 0.4540 - val_mae: 0.4540\n",
            "\n",
            " archi  [256, 128, 64, 32, 16, 8] \n",
            "\n",
            "\n",
            "\n",
            " FOLD\n",
            " 1 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 10ms/step - loss: 3.0234 - mae: 3.0234 - val_loss: 1.4969 - val_mae: 1.4969\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.9415 - mae: 0.9415 - val_loss: 0.8430 - val_mae: 0.8430\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.7223 - mae: 0.7223 - val_loss: 0.8608 - val_mae: 0.8608\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6878 - mae: 0.6878 - val_loss: 0.9578 - val_mae: 0.9578\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6731 - mae: 0.6731 - val_loss: 0.8908 - val_mae: 0.8908\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.0739 - mae: 1.0739 - val_loss: 0.5732 - val_mae: 0.5732\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6687 - mae: 0.6687 - val_loss: 0.4892 - val_mae: 0.4892\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6287 - mae: 0.6287 - val_loss: 0.4744 - val_mae: 0.4744\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6060 - mae: 0.6060 - val_loss: 0.4994 - val_mae: 0.4994\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5761 - mae: 0.5761 - val_loss: 0.7707 - val_mae: 0.7707\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5784 - mae: 0.5784 - val_loss: 0.6255 - val_mae: 0.6255\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5746 - mae: 0.5746 - val_loss: 0.5345 - val_mae: 0.5345\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5649 - mae: 0.5649 - val_loss: 0.5139 - val_mae: 0.5139\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5640 - mae: 0.5640 - val_loss: 0.5086 - val_mae: 0.5086\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5565 - mae: 0.5565 - val_loss: 0.5129 - val_mae: 0.5129\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5620 - mae: 0.5620 - val_loss: 0.4649 - val_mae: 0.4649\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5531 - mae: 0.5531 - val_loss: 0.6200 - val_mae: 0.6200\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5439 - mae: 0.5439 - val_loss: 0.5444 - val_mae: 0.5444\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5429 - mae: 0.5429 - val_loss: 0.5645 - val_mae: 0.5645\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5441 - mae: 0.5441 - val_loss: 0.4708 - val_mae: 0.4708\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5389 - mae: 0.5389 - val_loss: 0.5114 - val_mae: 0.5114\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5343 - mae: 0.5343 - val_loss: 0.5424 - val_mae: 0.5424\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5352 - mae: 0.5352 - val_loss: 0.5726 - val_mae: 0.5726\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5302 - mae: 0.5302 - val_loss: 0.5032 - val_mae: 0.5032\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5206 - mae: 0.5206 - val_loss: 0.5078 - val_mae: 0.5078\n",
            "\n",
            "\n",
            " FOLD\n",
            " 2 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 3.1359 - mae: 3.1359 - val_loss: 2.1278 - val_mae: 2.1278\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 1.5228 - mae: 1.5228 - val_loss: 1.0554 - val_mae: 1.0554\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.7652 - mae: 0.7652 - val_loss: 0.8614 - val_mae: 0.8614\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6874 - mae: 0.6874 - val_loss: 0.8884 - val_mae: 0.8884\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6582 - mae: 0.6582 - val_loss: 0.8846 - val_mae: 0.8846\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6346 - mae: 0.6346 - val_loss: 0.8612 - val_mae: 0.8612\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6116 - mae: 0.6116 - val_loss: 0.9131 - val_mae: 0.9131\n",
            "Epoch 8/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.5841 - mae: 0.5841 - val_loss: 0.9406 - val_mae: 0.9406\n",
            "Epoch 9/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.5603 - mae: 0.5603 - val_loss: 0.9852 - val_mae: 0.9852\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.0641 - mae: 1.0641 - val_loss: 0.3973 - val_mae: 0.3973\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7632 - mae: 0.7632 - val_loss: 0.3815 - val_mae: 0.3815\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7043 - mae: 0.7043 - val_loss: 0.3398 - val_mae: 0.3398\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6980 - mae: 0.6980 - val_loss: 0.4880 - val_mae: 0.4880\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6697 - mae: 0.6697 - val_loss: 0.4789 - val_mae: 0.4789\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6474 - mae: 0.6474 - val_loss: 0.5017 - val_mae: 0.5017\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6123 - mae: 0.6123 - val_loss: 0.3273 - val_mae: 0.3273\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6185 - mae: 0.6185 - val_loss: 0.4472 - val_mae: 0.4472\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6023 - mae: 0.6023 - val_loss: 0.4056 - val_mae: 0.4056\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5934 - mae: 0.5934 - val_loss: 0.4237 - val_mae: 0.4237\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5835 - mae: 0.5835 - val_loss: 0.4149 - val_mae: 0.4149\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5846 - mae: 0.5846 - val_loss: 0.3593 - val_mae: 0.3593\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5832 - mae: 0.5832 - val_loss: 0.3267 - val_mae: 0.3267\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5769 - mae: 0.5769 - val_loss: 0.3452 - val_mae: 0.3452\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5645 - mae: 0.5645 - val_loss: 0.3934 - val_mae: 0.3934\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5653 - mae: 0.5653 - val_loss: 0.4337 - val_mae: 0.4337\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5667 - mae: 0.5667 - val_loss: 0.3923 - val_mae: 0.3923\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5593 - mae: 0.5593 - val_loss: 0.3326 - val_mae: 0.3326\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5461 - mae: 0.5461 - val_loss: 0.3531 - val_mae: 0.3531\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5518 - mae: 0.5518 - val_loss: 0.3560 - val_mae: 0.3560\n",
            "\n",
            "\n",
            " FOLD\n",
            " 3 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 3.0192 - mae: 3.0192 - val_loss: 1.9855 - val_mae: 1.9855\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.6092 - mae: 1.6092 - val_loss: 1.2323 - val_mae: 1.2323\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.8321 - mae: 0.8321 - val_loss: 0.8799 - val_mae: 0.8799\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6808 - mae: 0.6808 - val_loss: 0.8976 - val_mae: 0.8976\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6498 - mae: 0.6498 - val_loss: 0.8865 - val_mae: 0.8865\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6232 - mae: 0.6232 - val_loss: 0.8957 - val_mae: 0.8957\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.1877 - mae: 1.1877 - val_loss: 0.3789 - val_mae: 0.3789\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7134 - mae: 0.7134 - val_loss: 0.4937 - val_mae: 0.4937\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6417 - mae: 0.6417 - val_loss: 0.5331 - val_mae: 0.5331\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6272 - mae: 0.6272 - val_loss: 0.4493 - val_mae: 0.4493\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6126 - mae: 0.6126 - val_loss: 0.5782 - val_mae: 0.5782\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6029 - mae: 0.6029 - val_loss: 0.5471 - val_mae: 0.5471\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5945 - mae: 0.5945 - val_loss: 0.5172 - val_mae: 0.5172\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5808 - mae: 0.5808 - val_loss: 0.4805 - val_mae: 0.4805\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5734 - mae: 0.5734 - val_loss: 0.4355 - val_mae: 0.4355\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5583 - mae: 0.5583 - val_loss: 0.5194 - val_mae: 0.5194\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5632 - mae: 0.5632 - val_loss: 0.4381 - val_mae: 0.4381\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5656 - mae: 0.5656 - val_loss: 0.4214 - val_mae: 0.4214\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5521 - mae: 0.5521 - val_loss: 0.5487 - val_mae: 0.5487\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5556 - mae: 0.5556 - val_loss: 0.5632 - val_mae: 0.5632\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5441 - mae: 0.5441 - val_loss: 0.5950 - val_mae: 0.5950\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5322 - mae: 0.5322 - val_loss: 0.4371 - val_mae: 0.4371\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5406 - mae: 0.5406 - val_loss: 0.4689 - val_mae: 0.4689\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5371 - mae: 0.5371 - val_loss: 0.5312 - val_mae: 0.5312\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5196 - mae: 0.5196 - val_loss: 0.4556 - val_mae: 0.4556\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5151 - mae: 0.5151 - val_loss: 0.6319 - val_mae: 0.6319\n",
            "\n",
            "\n",
            " FOLD\n",
            " 4 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 2.9873 - mae: 2.9873 - val_loss: 1.9751 - val_mae: 1.9751\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 1.3386 - mae: 1.3386 - val_loss: 0.9969 - val_mae: 0.9969\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.8048 - mae: 0.8048 - val_loss: 0.8790 - val_mae: 0.8790\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6816 - mae: 0.6816 - val_loss: 0.8633 - val_mae: 0.8633\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6579 - mae: 0.6579 - val_loss: 0.9063 - val_mae: 0.9063\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6252 - mae: 0.6252 - val_loss: 0.9067 - val_mae: 0.9067\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.5882 - mae: 0.5882 - val_loss: 0.8961 - val_mae: 0.8961\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 0.9942 - mae: 0.9942 - val_loss: 0.5879 - val_mae: 0.5879\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6881 - mae: 0.6881 - val_loss: 0.5370 - val_mae: 0.5370\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6538 - mae: 0.6538 - val_loss: 0.4474 - val_mae: 0.4474\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6280 - mae: 0.6280 - val_loss: 0.5119 - val_mae: 0.5119\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6231 - mae: 0.6231 - val_loss: 0.5162 - val_mae: 0.5162\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6106 - mae: 0.6106 - val_loss: 0.4190 - val_mae: 0.4190\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6053 - mae: 0.6053 - val_loss: 0.5314 - val_mae: 0.5314\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5929 - mae: 0.5929 - val_loss: 0.4730 - val_mae: 0.4730\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5940 - mae: 0.5940 - val_loss: 0.6015 - val_mae: 0.6015\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5810 - mae: 0.5810 - val_loss: 0.4544 - val_mae: 0.4544\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5841 - mae: 0.5841 - val_loss: 0.4263 - val_mae: 0.4263\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5762 - mae: 0.5762 - val_loss: 0.5414 - val_mae: 0.5414\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5667 - mae: 0.5667 - val_loss: 0.5092 - val_mae: 0.5092\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5616 - mae: 0.5616 - val_loss: 0.5427 - val_mae: 0.5427\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5506 - mae: 0.5506 - val_loss: 0.5608 - val_mae: 0.5608\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5533 - mae: 0.5533 - val_loss: 0.6071 - val_mae: 0.6071\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5502 - mae: 0.5502 - val_loss: 0.5051 - val_mae: 0.5051\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5434 - mae: 0.5434 - val_loss: 0.6815 - val_mae: 0.6815\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5421 - mae: 0.5421 - val_loss: 0.5373 - val_mae: 0.5373\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5317 - mae: 0.5317 - val_loss: 0.5697 - val_mae: 0.5697\n",
            "\n",
            "\n",
            " FOLD\n",
            " 5 \n",
            "train ncf\n",
            "\n",
            "Epoch 1/15\n",
            "49/49 [==============================] - 1s 9ms/step - loss: 3.7202 - mae: 3.7202 - val_loss: 3.1192 - val_mae: 3.1192\n",
            "Epoch 2/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 2.5626 - mae: 2.5626 - val_loss: 1.9761 - val_mae: 1.9761\n",
            "Epoch 3/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 1.2732 - mae: 1.2732 - val_loss: 1.0847 - val_mae: 1.0847\n",
            "Epoch 4/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.7629 - mae: 0.7629 - val_loss: 0.8852 - val_mae: 0.8852\n",
            "Epoch 5/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6804 - mae: 0.6804 - val_loss: 0.8865 - val_mae: 0.8865\n",
            "Epoch 6/15\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 0.6567 - mae: 0.6567 - val_loss: 0.8903 - val_mae: 0.8903\n",
            "Epoch 7/15\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 0.6387 - mae: 0.6387 - val_loss: 0.9007 - val_mae: 0.9007\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.0686 - mae: 1.0686 - val_loss: 0.5038 - val_mae: 0.5038\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7064 - mae: 0.7064 - val_loss: 0.4671 - val_mae: 0.4671\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6501 - mae: 0.6501 - val_loss: 0.4324 - val_mae: 0.4324\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6249 - mae: 0.6249 - val_loss: 0.3943 - val_mae: 0.3943\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6023 - mae: 0.6023 - val_loss: 0.4510 - val_mae: 0.4510\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6044 - mae: 0.6044 - val_loss: 0.4190 - val_mae: 0.4190\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6001 - mae: 0.6001 - val_loss: 0.4837 - val_mae: 0.4837\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5833 - mae: 0.5833 - val_loss: 0.4117 - val_mae: 0.4117\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5886 - mae: 0.5886 - val_loss: 0.3956 - val_mae: 0.3956\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5786 - mae: 0.5786 - val_loss: 0.3850 - val_mae: 0.3850\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5751 - mae: 0.5751 - val_loss: 0.4239 - val_mae: 0.4239\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5778 - mae: 0.5778 - val_loss: 0.5198 - val_mae: 0.5198\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5644 - mae: 0.5644 - val_loss: 0.4302 - val_mae: 0.4302\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5645 - mae: 0.5645 - val_loss: 0.3969 - val_mae: 0.3969\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5474 - mae: 0.5474 - val_loss: 0.4331 - val_mae: 0.4331\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5551 - mae: 0.5551 - val_loss: 0.3623 - val_mae: 0.3623\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5511 - mae: 0.5511 - val_loss: 0.3820 - val_mae: 0.3820\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5451 - mae: 0.5451 - val_loss: 0.4208 - val_mae: 0.4208\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5342 - mae: 0.5342 - val_loss: 0.4001 - val_mae: 0.4001\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5334 - mae: 0.5334 - val_loss: 0.4147 - val_mae: 0.4147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'mae agg',agg_mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIIcyH3r2JOh",
        "outputId": "fbe0dda3-0ea4-4055-bf7c-82afbde60fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('mae agg',\n",
              " [1.070262916783451,\n",
              "  1.0581976170476108,\n",
              "  0.9625912060844712,\n",
              "  0.9071557326172511,\n",
              "  0.9100792068007845,\n",
              "  0.9006398229475616])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'rmse agg',agg_rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkU604Du2Obn",
        "outputId": "9a565414-3327-47bd-8e28-d4f9eb8fc831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('rmse agg',\n",
              " [1.3479597624893482,\n",
              "  1.313950318141593,\n",
              "  1.2218635424893591,\n",
              "  1.1658835874494107,\n",
              "  1.1520819905577078,\n",
              "  1.1330694774032646])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_hist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nrYFMs3sY11",
        "outputId": "49a72a26-10dc-4396-88fa-224499f4b6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9723327245741675,\n",
              " 0.9415638306140464,\n",
              " 0.9054579816046496,\n",
              " 0.8769407985301013,\n",
              " 0.8462815805532193,\n",
              " 0.855793846539972]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame()\n",
        "results['archi'] = archi\n",
        "results['mean mae'] = mae_hist \n",
        "results['mae_cleanliness'] = mae_cleanliness \n",
        "results['mae_location'] =  mae_loc \n",
        "results['mae_rooms'] = mae_rooms \n",
        "results['mae_service'] = mae_srv\n",
        "\n",
        "results['mae_value'] = mae_value\n",
        "\n",
        "results['mean rmse'] = rmse_hist\n",
        "results['rmse_cleanliness'] =rmse_cleanliness \n",
        "results['rmse_location'] =  rmse_loc \n",
        "results['rmse_rooms'] = rmse_rooms \n",
        "results['rmse_service'] = rmse_srv\n",
        "\n",
        "results['rmse_value'] = rmse_value\n",
        "\n",
        "\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "WxduTD1QSUM2",
        "outputId": "a2a73c4e-edfb-4411-cf29-f5d69101e6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       archi  mean mae  mae_cleanliness  mae_location  \\\n",
              "0                        [8]  0.969502         0.925041      0.829838   \n",
              "1                    [16, 8]  0.941580         0.897034      0.790985   \n",
              "2                [32, 16, 8]  0.904059         0.857614      0.738841   \n",
              "3            [64, 32, 16, 8]  0.869094         0.810894      0.730262   \n",
              "4       [128, 64, 32, 16, 8]  0.841244         0.774632      0.709174   \n",
              "5  [256, 128, 64, 32, 16, 8]  0.843770         0.793567      0.724817   \n",
              "\n",
              "   mae_rooms  mae_service  mae_value  mean rmse  rmse_cleanliness  \\\n",
              "0   1.010519     1.010491   1.071620   1.285582          1.250495   \n",
              "1   0.982835     0.989134   1.047914   1.241798          1.201566   \n",
              "2   0.955998     0.951862   1.015979   1.196941          1.153371   \n",
              "3   0.918169     0.904441   0.981704   1.164874          1.113200   \n",
              "4   0.890277     0.883401   0.948737   1.138477          1.080265   \n",
              "5   0.873981     0.885111   0.941376   1.120253          1.069172   \n",
              "\n",
              "   rmse_location  rmse_rooms  rmse_service  rmse_value  \n",
              "0       1.135321    1.314867      1.356394    1.370833  \n",
              "1       1.076915    1.271667      1.318307    1.340532  \n",
              "2       1.013716    1.237696      1.274431    1.305489  \n",
              "3       1.000416    1.202064      1.234979    1.273714  \n",
              "4       0.983548    1.175184      1.213932    1.239454  \n",
              "5       0.971493    1.141271      1.200241    1.219090  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faae3516-6a3e-474f-9cb5-cf7d09e9d1ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>archi</th>\n",
              "      <th>mean mae</th>\n",
              "      <th>mae_cleanliness</th>\n",
              "      <th>mae_location</th>\n",
              "      <th>mae_rooms</th>\n",
              "      <th>mae_service</th>\n",
              "      <th>mae_value</th>\n",
              "      <th>mean rmse</th>\n",
              "      <th>rmse_cleanliness</th>\n",
              "      <th>rmse_location</th>\n",
              "      <th>rmse_rooms</th>\n",
              "      <th>rmse_service</th>\n",
              "      <th>rmse_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[8]</td>\n",
              "      <td>0.969502</td>\n",
              "      <td>0.925041</td>\n",
              "      <td>0.829838</td>\n",
              "      <td>1.010519</td>\n",
              "      <td>1.010491</td>\n",
              "      <td>1.071620</td>\n",
              "      <td>1.285582</td>\n",
              "      <td>1.250495</td>\n",
              "      <td>1.135321</td>\n",
              "      <td>1.314867</td>\n",
              "      <td>1.356394</td>\n",
              "      <td>1.370833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[16, 8]</td>\n",
              "      <td>0.941580</td>\n",
              "      <td>0.897034</td>\n",
              "      <td>0.790985</td>\n",
              "      <td>0.982835</td>\n",
              "      <td>0.989134</td>\n",
              "      <td>1.047914</td>\n",
              "      <td>1.241798</td>\n",
              "      <td>1.201566</td>\n",
              "      <td>1.076915</td>\n",
              "      <td>1.271667</td>\n",
              "      <td>1.318307</td>\n",
              "      <td>1.340532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[32, 16, 8]</td>\n",
              "      <td>0.904059</td>\n",
              "      <td>0.857614</td>\n",
              "      <td>0.738841</td>\n",
              "      <td>0.955998</td>\n",
              "      <td>0.951862</td>\n",
              "      <td>1.015979</td>\n",
              "      <td>1.196941</td>\n",
              "      <td>1.153371</td>\n",
              "      <td>1.013716</td>\n",
              "      <td>1.237696</td>\n",
              "      <td>1.274431</td>\n",
              "      <td>1.305489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[64, 32, 16, 8]</td>\n",
              "      <td>0.869094</td>\n",
              "      <td>0.810894</td>\n",
              "      <td>0.730262</td>\n",
              "      <td>0.918169</td>\n",
              "      <td>0.904441</td>\n",
              "      <td>0.981704</td>\n",
              "      <td>1.164874</td>\n",
              "      <td>1.113200</td>\n",
              "      <td>1.000416</td>\n",
              "      <td>1.202064</td>\n",
              "      <td>1.234979</td>\n",
              "      <td>1.273714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[128, 64, 32, 16, 8]</td>\n",
              "      <td>0.841244</td>\n",
              "      <td>0.774632</td>\n",
              "      <td>0.709174</td>\n",
              "      <td>0.890277</td>\n",
              "      <td>0.883401</td>\n",
              "      <td>0.948737</td>\n",
              "      <td>1.138477</td>\n",
              "      <td>1.080265</td>\n",
              "      <td>0.983548</td>\n",
              "      <td>1.175184</td>\n",
              "      <td>1.213932</td>\n",
              "      <td>1.239454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[256, 128, 64, 32, 16, 8]</td>\n",
              "      <td>0.843770</td>\n",
              "      <td>0.793567</td>\n",
              "      <td>0.724817</td>\n",
              "      <td>0.873981</td>\n",
              "      <td>0.885111</td>\n",
              "      <td>0.941376</td>\n",
              "      <td>1.120253</td>\n",
              "      <td>1.069172</td>\n",
              "      <td>0.971493</td>\n",
              "      <td>1.141271</td>\n",
              "      <td>1.200241</td>\n",
              "      <td>1.219090</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faae3516-6a3e-474f-9cb5-cf7d09e9d1ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-faae3516-6a3e-474f-9cb5-cf7d09e9d1ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-faae3516-6a3e-474f-9cb5-cf7d09e9d1ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.to_excel('NCF_tripadvisor.xlsx',index=False)"
      ],
      "metadata": {
        "id": "lFgFXtHvaHMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp 'NCF_tripadvisor.xlsx' '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "uzhRshgqaRIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#save agg model"
      ],
      "metadata": {
        "id": "hFWqMVrEHQR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg_model = agg_()\n",
        "y_train = train_data[['cleanliness','location','rooms','service','value']].values\n",
        "over_train = train_data['overall'].values\n",
        "\n",
        "agg_model.fit(y_train,over_train,epochs=20,batch_size=64)"
      ],
      "metadata": {
        "id": "tLzFO0SjaWg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d442e8d-9861-425e-f7d4-89876faaea8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "121/121 [==============================] - 4s 3ms/step - loss: 0.9184 - mae: 0.9184\n",
            "Epoch 2/20\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.6541 - mae: 0.6541\n",
            "Epoch 3/20\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.6171 - mae: 0.6171\n",
            "Epoch 4/20\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.6050 - mae: 0.6050\n",
            "Epoch 5/20\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.5914 - mae: 0.5914\n",
            "Epoch 6/20\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.5798 - mae: 0.5798\n",
            "Epoch 7/20\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.5770 - mae: 0.5770\n",
            "Epoch 8/20\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.5813 - mae: 0.5813\n",
            "Epoch 9/20\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.5661 - mae: 0.5661\n",
            "Epoch 10/20\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.5730 - mae: 0.5730\n",
            "Epoch 11/20\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.5686 - mae: 0.5686\n",
            "Epoch 12/20\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.5584 - mae: 0.5584\n",
            "Epoch 13/20\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.5461 - mae: 0.5461\n",
            "Epoch 14/20\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5518 - mae: 0.5518\n",
            "Epoch 15/20\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5418 - mae: 0.5418\n",
            "Epoch 16/20\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5395 - mae: 0.5395\n",
            "Epoch 17/20\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.5388 - mae: 0.5388\n",
            "Epoch 18/20\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.5339 - mae: 0.5339\n",
            "Epoch 19/20\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.5220 - mae: 0.5220\n",
            "Epoch 20/20\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5169 - mae: 0.5169\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43e0216c90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg_model.save('agg.h5')"
      ],
      "metadata": {
        "id": "QQ-LpA1xH5PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IhTY7RB4IAXQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}