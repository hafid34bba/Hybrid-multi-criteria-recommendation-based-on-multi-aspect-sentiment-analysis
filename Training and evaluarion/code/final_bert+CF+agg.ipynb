{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_bert+CF+agg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DosQTZqMMoR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Dense, Input, Flatten, concatenate,LSTM,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "#mae(ts_data[['cleanliness','location','rooms','service','value']], pred_test_data )"
      ],
      "metadata": {
        "id": "u6Vku5dDfJOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agg_():\n",
        "  inp_agg = Input(shape=(5,), name = 'creteria_input')\n",
        "  agg = Dense(64,activation='relu')(inp_agg)\n",
        "  agg = Dropout(0.2)(agg)\n",
        "  agg = Dense(128,activation='relu')(inp_agg)\n",
        "  agg = Dropout(0.3)(agg)\n",
        "  agg = Dense(64,activation='relu')(inp_agg)\n",
        "  agg = Dropout(0.2)(agg)\n",
        "  agg = Dense(32,activation='relu')(agg)\n",
        "  agg = Dropout(0.2)(agg)\n",
        "\n",
        "  out= Dense(1,activation='relu')(agg)\n",
        "\n",
        "  agg_model = Model(inputs=inp_agg, \n",
        "                    outputs=out)\n",
        "\n",
        "  agg_model.compile(optimizer='adam',loss='mae',metrics=['mae'])\n",
        "  \n",
        "  return agg_model"
      ],
      "metadata": {
        "id": "-Qdun0OCLWwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "kf = KFold(n_splits=5,random_state=24,shuffle=True)\n",
        "from sklearn.neighbors import DistanceMetric\n",
        "dist = DistanceMetric.get_metric('hamming')\n",
        "mae_hist = []\n",
        "mae_cleanliness = []\n",
        "mae_loc = []\n",
        "mae_rooms = []\n",
        "mae_srv = []\n",
        "\n",
        "mae_value = []\n",
        "\n",
        "rmse_hist = []\n",
        "rmse_cleanliness = []\n",
        "rmse_loc = []\n",
        "rmse_rooms = []\n",
        "rmse_srv = []\n",
        "\n",
        "rmse_value = []\n",
        "\n",
        "agg_mae = []\n",
        "agg_rmse = []\n",
        "\n",
        "k = 3\n",
        "f = 1\n",
        "\n",
        "for i in range(1,6):\n",
        "    train_data = pd.read_csv('/content/drive/MyDrive/Trip_fold_with_sentiment'+str(i)+'_train.csv')\n",
        "    y_train  =train_data[['cleanliness','location','rooms','service','value']].values\n",
        "    test_data = pd.read_csv('/content/drive/MyDrive/Trip_fold_with_sentiment'+str(i)+'_test.csv')\n",
        "    y_test = test_data[['cleanliness','location','rooms','service','value']].values\n",
        "    over_train = train_data.overall.values\n",
        "    over_test = test_data.overall.values\n",
        "\n",
        "    pred_Bert_cf = []\n",
        "    print('fold',i)\n",
        "    cmp=0\n",
        "    for idx,row in test_data.iterrows():\n",
        "      cmp+=1\n",
        "      precedent_data = train_data[train_data['user_id']==row['user_id']]\n",
        "      precedent_hotels = precedent_data.offering_id.values\n",
        "      prcd_reviews = precedent_data.text.values\n",
        "      hotel_id = row['offering_id']\n",
        "      \n",
        "      if hotel_id in train_data.offering_id.values:\n",
        "        precedent_data = train_data[train_data['user_id']==row['user_id']]\n",
        "\n",
        "        if precedent_data.shape[0] > 0:\n",
        "\n",
        "          precedent_hotels = precedent_data.offering_id.values\n",
        "          prcd_reviews = precedent_data.sentiment_score.values\n",
        "          \n",
        "        \n",
        "          prcedent_data_sentiment_review = {}\n",
        "          for h_id,rev in zip(precedent_hotels,prcd_reviews):\n",
        "            \n",
        "            \n",
        "            prcedent_data_sentiment_review[h_id] = rev\n",
        "            \n",
        "          \n",
        "          user = row['user_id']\n",
        "\n",
        "          maybe_sim_users = []\n",
        "          sim = {}\n",
        "          if cmp%100==0:\n",
        "            print('rest',test_data.shape[0] - cmp)\n",
        "\n",
        "          users = train_data[train_data['offering_id']==hotel_id].user_id.unique()\n",
        "          for user1 in users:\n",
        "            if (user1 != user):\n",
        "              \n",
        "\n",
        "              user1_data = train_data[train_data['user_id']==user1]\n",
        "              sim_items = set(precedent_hotels).intersection(set(user1_data.offering_id.values))\n",
        "              if len(sim_items) > 1:\n",
        "                  \n",
        "                  maybe_sim_users.append(user1)\n",
        "                \n",
        "                  user_rat = []\n",
        "                  user1_rat = []\n",
        "                  for item in sim_items:\n",
        "                    \n",
        "                    user_rat.append(prcedent_data_sentiment_review[item])\n",
        "\n",
        "                  for item in sim_items:\n",
        "                    rev = user1_data[user1_data['offering_id']==item].sentiment_score.values\n",
        "                    \n",
        "                    \n",
        "                    user1_rat.append(rev[0])\n",
        "                  \n",
        "                  if (1 - dist.pairwise([user_rat],[user1_rat])[0][0])> 0.5:\n",
        "                    sim[user1] = 1 - dist.pairwise([user_rat],[user1_rat])[0][0]\n",
        "          \n",
        "          if len(sim.keys())>0: #similar users\n",
        "            rat = [0.0,0.0,0.0,0.0,0.0]\n",
        "            sum_sim = 0.0\n",
        "            for user1 in list(sim.keys())[:k]:\n",
        "              rat += sim[user1] * train_data[(train_data['user_id']==user1) & (train_data['offering_id']==hotel_id ) ][['cleanliness','location','rooms','service','value']].values[0]\n",
        "              sum_sim+= sim[user1]\n",
        "            rat = rat / sum_sim\n",
        "          \n",
        "          \n",
        "          else : #no similar users\n",
        "            rat = [0.0,0.0,0.0,0.0,0.0]\n",
        "            for i,col in zip([0,1,2,3,4],['cleanliness','location','rooms','service','value']):\n",
        "              rat[i] = np.mean(train_data[train_data['offering_id']==hotel_id][[col]].values)\n",
        "          \n",
        "        else: #new_user\n",
        "            rat = [0.0,0.0,0.0,0.0,0.0]\n",
        "            for i,col in zip([0,1,2,3,4],['cleanliness','location','rooms','service','value']):\n",
        "              rat[i] = np.mean(train_data[train_data['offering_id']==hotel_id][[col]].values)  \n",
        "\n",
        "      elif train_data[train_data['user_id']==row['user_id']].shape[0]>0: #new_item\n",
        "        rat = [0.0,0.0,0.0,0.0,0.0]\n",
        "        for i,col in zip([0,1,2,3,4],['cleanliness','location','rooms','service','value']):\n",
        "            rat[i] = np.mean(precedent_data[[col]].values)\n",
        "      else: #new_user , new_item\n",
        "        #rnd_petubation = random.uniform(-1,1)\n",
        "        #val = rnd_petubation + 3.0\n",
        "        rat = [train_data['cleanliness'].mean(),train_data['location'].mean(),train_data['rooms'].mean()\n",
        "            ,train_data['service'],train_data['value']]\n",
        "      pred_Bert_cf.append(rat.copy())\n",
        "\n",
        "    pred_Bert_cf = np.array(pred_Bert_cf)\n",
        "    pred_test_data = np.copy(pred_Bert_cf)\n",
        "    mae_cleanliness.append(mae(pred_test_data[:,0],y_test[:,0]))\n",
        "    mae_loc.append(mae(pred_test_data[:,1],y_test[:,1]))\n",
        "    mae_rooms.append(mae(pred_test_data[:,2],y_test[:,2]))\n",
        "    mae_srv.append(mae(pred_test_data[:,3],y_test[:,3]))\n",
        "    \n",
        "    mae_value.append(mae(pred_test_data[:,4],y_test[:,4]))\n",
        "    mae_hist.append(mae(pred_test_data,y_test))\n",
        "      \n",
        "    rmse_cleanliness.append(mse(pred_test_data[:,0],y_test[:,0], squared=False))\n",
        "    rmse_loc.append(mse(pred_test_data[:,1],y_test[:,1], squared=False))\n",
        "    rmse_rooms.append(mse(pred_test_data[:,2],y_test[:,2], squared=False))\n",
        "    rmse_srv.append(mse(pred_test_data[:,3],y_test[:,3], squared=False))\n",
        "  \n",
        "    rmse_value.append(mse(pred_test_data[:,4],y_test[:,4], squared=False))\n",
        "    rmse_hist.append(mse(pred_test_data,y_test, squared=False))\n",
        "\n",
        "    print(mae_hist)\n",
        "    print(rmse_hist)\n",
        "\n",
        "    agg_model = agg_()\n",
        "\n",
        "    #agg_train_inp = model.predict([X_user_train,X_hotel_train])\n",
        "    print('\\n train agg model \\n')\n",
        "    agg_model.fit(y_train,over_train,validation_split=0.1,epochs=20,batch_size=64)\n",
        "\n",
        "    agg_mae.append(mae(agg_model.predict(pred_test_data),over_test))\n",
        "    agg_rmse.append(mse(agg_model.predict(pred_test_data),over_test,squared=False))\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8YjT_x9KpVu",
        "outputId": "4ad5409e-7380-4eda-c74c-e786233e59ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_distance_metric.py:14: FutureWarning: sklearn.neighbors.DistanceMetric has been moved to sklearn.metrics.DistanceMetric in 1.0. This import path will be removed in 1.3\n",
            "  category=FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 1\n",
            "rest 1834\n",
            "rest 1734\n",
            "rest 1634\n",
            "rest 1534\n",
            "rest 1434\n",
            "rest 1334\n",
            "rest 1234\n",
            "rest 1134\n",
            "rest 1034\n",
            "rest 934\n",
            "rest 734\n",
            "rest 634\n",
            "rest 534\n",
            "rest 434\n",
            "rest 334\n",
            "rest 234\n",
            "rest 134\n",
            "rest 34\n",
            "[0.8279933581120865]\n",
            "[1.1292571438017642]\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 3s 4ms/step - loss: 1.0297 - mae: 1.0297 - val_loss: 0.4584 - val_mae: 0.4584\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6951 - mae: 0.6951 - val_loss: 0.4131 - val_mae: 0.4131\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6380 - mae: 0.6380 - val_loss: 0.4661 - val_mae: 0.4661\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6256 - mae: 0.6256 - val_loss: 0.5173 - val_mae: 0.5173\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6082 - mae: 0.6082 - val_loss: 0.5168 - val_mae: 0.5168\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5963 - mae: 0.5963 - val_loss: 0.4350 - val_mae: 0.4350\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5934 - mae: 0.5934 - val_loss: 0.4949 - val_mae: 0.4949\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5783 - mae: 0.5783 - val_loss: 0.5162 - val_mae: 0.5162\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5684 - mae: 0.5684 - val_loss: 0.5196 - val_mae: 0.5196\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5698 - mae: 0.5698 - val_loss: 0.5222 - val_mae: 0.5222\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5540 - mae: 0.5540 - val_loss: 0.5589 - val_mae: 0.5589\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5640 - mae: 0.5640 - val_loss: 0.3515 - val_mae: 0.3515\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5564 - mae: 0.5564 - val_loss: 0.4187 - val_mae: 0.4187\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5445 - mae: 0.5445 - val_loss: 0.5224 - val_mae: 0.5224\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5404 - mae: 0.5404 - val_loss: 0.4054 - val_mae: 0.4054\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5383 - mae: 0.5383 - val_loss: 0.6388 - val_mae: 0.6388\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5348 - mae: 0.5348 - val_loss: 0.3976 - val_mae: 0.3976\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5350 - mae: 0.5350 - val_loss: 0.5916 - val_mae: 0.5916\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5166 - mae: 0.5166 - val_loss: 0.5024 - val_mae: 0.5024\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5140 - mae: 0.5140 - val_loss: 0.4887 - val_mae: 0.4887\n",
            "fold 2\n",
            "rest 1834\n",
            "rest 1734\n",
            "rest 1634\n",
            "rest 1534\n",
            "rest 1334\n",
            "rest 1234\n",
            "rest 1134\n",
            "rest 1034\n",
            "rest 934\n",
            "rest 834\n",
            "rest 734\n",
            "rest 634\n",
            "rest 534\n",
            "rest 434\n",
            "rest 334\n",
            "rest 234\n",
            "rest 134\n",
            "rest 34\n",
            "[0.8279933581120865, 0.8141036991423471]\n",
            "[1.1292571438017642, 1.1104464243017358]\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 0.8108 - mae: 0.8108 - val_loss: 0.7122 - val_mae: 0.7122\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6512 - mae: 0.6512 - val_loss: 0.7805 - val_mae: 0.7805\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6142 - mae: 0.6142 - val_loss: 0.7434 - val_mae: 0.7434\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5955 - mae: 0.5955 - val_loss: 0.5810 - val_mae: 0.5810\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6025 - mae: 0.6025 - val_loss: 0.7509 - val_mae: 0.7509\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5969 - mae: 0.5969 - val_loss: 0.5995 - val_mae: 0.5995\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5838 - mae: 0.5838 - val_loss: 0.5442 - val_mae: 0.5442\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5847 - mae: 0.5847 - val_loss: 0.6364 - val_mae: 0.6364\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5752 - mae: 0.5752 - val_loss: 0.5613 - val_mae: 0.5613\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5575 - mae: 0.5575 - val_loss: 0.6480 - val_mae: 0.6480\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5541 - mae: 0.5541 - val_loss: 0.6605 - val_mae: 0.6605\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5513 - mae: 0.5513 - val_loss: 0.6372 - val_mae: 0.6372\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5512 - mae: 0.5512 - val_loss: 0.5789 - val_mae: 0.5789\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5418 - mae: 0.5418 - val_loss: 0.7315 - val_mae: 0.7315\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5387 - mae: 0.5387 - val_loss: 0.6580 - val_mae: 0.6580\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5268 - mae: 0.5268 - val_loss: 0.6229 - val_mae: 0.6229\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5243 - mae: 0.5243 - val_loss: 0.6503 - val_mae: 0.6503\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5325 - mae: 0.5325 - val_loss: 0.5702 - val_mae: 0.5702\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5256 - mae: 0.5256 - val_loss: 0.6284 - val_mae: 0.6284\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5210 - mae: 0.5210 - val_loss: 0.6178 - val_mae: 0.6178\n",
            "fold 3\n",
            "rest 1834\n",
            "rest 1734\n",
            "rest 1634\n",
            "rest 1534\n",
            "rest 1434\n",
            "rest 1334\n",
            "rest 1234\n",
            "rest 1134\n",
            "rest 1034\n",
            "rest 834\n",
            "rest 734\n",
            "rest 634\n",
            "rest 534\n",
            "rest 434\n",
            "rest 334\n",
            "rest 234\n",
            "rest 134\n",
            "rest 34\n",
            "[0.8279933581120865, 0.8141036991423471, 0.8280769645744359]\n",
            "[1.1292571438017642, 1.1104464243017358, 1.1288463747214934]\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.0826 - mae: 1.0826 - val_loss: 0.5278 - val_mae: 0.5278\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7368 - mae: 0.7368 - val_loss: 0.4015 - val_mae: 0.4015\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6898 - mae: 0.6898 - val_loss: 0.4310 - val_mae: 0.4310\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6350 - mae: 0.6350 - val_loss: 0.4094 - val_mae: 0.4094\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6436 - mae: 0.6436 - val_loss: 0.5390 - val_mae: 0.5390\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6315 - mae: 0.6315 - val_loss: 0.5556 - val_mae: 0.5556\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6159 - mae: 0.6159 - val_loss: 0.5749 - val_mae: 0.5749\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6195 - mae: 0.6195 - val_loss: 0.5330 - val_mae: 0.5330\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6004 - mae: 0.6004 - val_loss: 0.4868 - val_mae: 0.4868\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5924 - mae: 0.5924 - val_loss: 0.4626 - val_mae: 0.4626\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5931 - mae: 0.5931 - val_loss: 0.4279 - val_mae: 0.4279\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5810 - mae: 0.5810 - val_loss: 0.4997 - val_mae: 0.4997\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5715 - mae: 0.5715 - val_loss: 0.3831 - val_mae: 0.3831\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5677 - mae: 0.5677 - val_loss: 0.3784 - val_mae: 0.3784\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5537 - mae: 0.5537 - val_loss: 0.4348 - val_mae: 0.4348\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5661 - mae: 0.5661 - val_loss: 0.4156 - val_mae: 0.4156\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5578 - mae: 0.5578 - val_loss: 0.4375 - val_mae: 0.4375\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5473 - mae: 0.5473 - val_loss: 0.4795 - val_mae: 0.4795\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5497 - mae: 0.5497 - val_loss: 0.3682 - val_mae: 0.3682\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5393 - mae: 0.5393 - val_loss: 0.5023 - val_mae: 0.5023\n",
            "fold 4\n",
            "rest 1833\n",
            "rest 1733\n",
            "rest 1633\n",
            "rest 1533\n",
            "rest 1433\n",
            "rest 1333\n",
            "rest 1233\n",
            "rest 1133\n",
            "rest 1033\n",
            "rest 933\n",
            "rest 833\n",
            "rest 733\n",
            "rest 633\n",
            "rest 533\n",
            "rest 433\n",
            "rest 333\n",
            "rest 233\n",
            "rest 133\n",
            "rest 33\n",
            "[0.8279933581120865, 0.8141036991423471, 0.8280769645744359, 0.8186444212659918]\n",
            "[1.1292571438017642, 1.1104464243017358, 1.1288463747214934, 1.1065956690507595]\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 1.1316 - mae: 1.1316 - val_loss: 0.4670 - val_mae: 0.4670\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7099 - mae: 0.7099 - val_loss: 0.3655 - val_mae: 0.3655\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6456 - mae: 0.6456 - val_loss: 0.5523 - val_mae: 0.5523\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6247 - mae: 0.6247 - val_loss: 0.4035 - val_mae: 0.4035\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6136 - mae: 0.6136 - val_loss: 0.4627 - val_mae: 0.4627\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6155 - mae: 0.6155 - val_loss: 0.4948 - val_mae: 0.4948\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6039 - mae: 0.6039 - val_loss: 0.5129 - val_mae: 0.5129\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5920 - mae: 0.5920 - val_loss: 0.4895 - val_mae: 0.4895\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5886 - mae: 0.5886 - val_loss: 0.5461 - val_mae: 0.5461\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5878 - mae: 0.5878 - val_loss: 0.4710 - val_mae: 0.4710\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5890 - mae: 0.5890 - val_loss: 0.5488 - val_mae: 0.5488\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5729 - mae: 0.5729 - val_loss: 0.6437 - val_mae: 0.6437\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5702 - mae: 0.5702 - val_loss: 0.6267 - val_mae: 0.6267\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5636 - mae: 0.5636 - val_loss: 0.5616 - val_mae: 0.5616\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5614 - mae: 0.5614 - val_loss: 0.5443 - val_mae: 0.5443\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5515 - mae: 0.5515 - val_loss: 0.5162 - val_mae: 0.5162\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5523 - mae: 0.5523 - val_loss: 0.5315 - val_mae: 0.5315\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5470 - mae: 0.5470 - val_loss: 0.5455 - val_mae: 0.5455\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5403 - mae: 0.5403 - val_loss: 0.5381 - val_mae: 0.5381\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5296 - mae: 0.5296 - val_loss: 0.5808 - val_mae: 0.5808\n",
            "fold 5\n",
            "rest 1833\n",
            "rest 1733\n",
            "rest 1633\n",
            "rest 1533\n",
            "rest 1433\n",
            "rest 1333\n",
            "rest 1233\n",
            "rest 1133\n",
            "rest 1033\n",
            "rest 833\n",
            "rest 733\n",
            "rest 633\n",
            "rest 533\n",
            "rest 433\n",
            "rest 333\n",
            "rest 233\n",
            "rest 133\n",
            "rest 33\n",
            "[0.8279933581120865, 0.8141036991423471, 0.8280769645744359, 0.8186444212659918, 0.8341973154394932]\n",
            "[1.1292571438017642, 1.1104464243017358, 1.1288463747214934, 1.1065956690507595, 1.1290257450674697]\n",
            "\n",
            " train agg model \n",
            "\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 1s 4ms/step - loss: 0.9988 - mae: 0.9988 - val_loss: 0.7434 - val_mae: 0.7434\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7681 - mae: 0.7681 - val_loss: 0.4230 - val_mae: 0.4230\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6987 - mae: 0.6987 - val_loss: 0.5504 - val_mae: 0.5504\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6714 - mae: 0.6714 - val_loss: 0.6139 - val_mae: 0.6139\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6408 - mae: 0.6408 - val_loss: 0.5730 - val_mae: 0.5730\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6271 - mae: 0.6271 - val_loss: 0.4096 - val_mae: 0.4096\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6174 - mae: 0.6174 - val_loss: 0.5602 - val_mae: 0.5602\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6184 - mae: 0.6184 - val_loss: 0.4560 - val_mae: 0.4560\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6099 - mae: 0.6099 - val_loss: 0.4781 - val_mae: 0.4781\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5977 - mae: 0.5977 - val_loss: 0.3506 - val_mae: 0.3506\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5838 - mae: 0.5838 - val_loss: 0.4492 - val_mae: 0.4492\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5782 - mae: 0.5782 - val_loss: 0.4915 - val_mae: 0.4915\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5644 - mae: 0.5644 - val_loss: 0.3990 - val_mae: 0.3990\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5676 - mae: 0.5676 - val_loss: 0.4294 - val_mae: 0.4294\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5722 - mae: 0.5722 - val_loss: 0.3971 - val_mae: 0.3971\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5580 - mae: 0.5580 - val_loss: 0.4052 - val_mae: 0.4052\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5608 - mae: 0.5608 - val_loss: 0.3716 - val_mae: 0.3716\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5541 - mae: 0.5541 - val_loss: 0.3837 - val_mae: 0.3837\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5530 - mae: 0.5530 - val_loss: 0.4341 - val_mae: 0.4341\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5435 - mae: 0.5435 - val_loss: 0.3949 - val_mae: 0.3949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'agg mae',agg_mae,np.mean(agg_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t06OqSeMcLJ",
        "outputId": "5005920b-7434-41bc-feb0-f505f80a3a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('agg mae',\n",
              " [0.8761254785719184,\n",
              "  0.9875411823962073,\n",
              "  0.9212151236963124,\n",
              "  0.9486092663896682,\n",
              "  0.8823075190271298],\n",
              " 0.9231597140162473)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N7V33CThN-6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'agg rmse',agg_rmse,np.mean(agg_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hORkObokMgGt",
        "outputId": "17751116-1b87-4eef-e273-bb7de74d7616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('agg rmse',\n",
              " [1.1170878966998103,\n",
              "  1.1863559737246758,\n",
              "  1.154760625816642,\n",
              "  1.1577110685436627,\n",
              "  1.138650263052804],\n",
              " 1.1509131655675189)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('mean_mae',mae_hist , np.mean(mae_hist))\n",
        "print('mae_cleanliness',mae_cleanliness ,np.mean(mae_cleanliness ))\n",
        "print('mae_loc',mae_loc,np.mean(mae_loc))\n",
        "print('mae_rooms',mae_rooms,np.mean(mae_rooms))\n",
        "print('mae_srv',mae_srv,np.mean(mae_srv))\n",
        "\n",
        "print('mae_value',mae_value,np.mean(mae_value))\n",
        "\n",
        "print('rmse_hist',rmse_hist,np.mean(rmse_hist))\n",
        "print('rmse_cleanliness',rmse_cleanliness,np.mean(rmse_cleanliness))\n",
        "print('rmse_loc',rmse_loc,np.mean(rmse_loc))\n",
        "print('rmse_rooms',rmse_rooms,np.mean(rmse_rooms))\n",
        "print('rmse_srv',rmse_srv,np.mean(rmse_srv))\n",
        "\n",
        "print('rmse_value',rmse_value,np.mean(rmse_value))"
      ],
      "metadata": {
        "id": "x15Q3D47a-zU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7107c25e-e4cb-438e-a323-7ad943dd9c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_mae [0.8279933581120865, 0.8141036991423471, 0.8280769645744359, 0.8186444212659918, 0.8341973154394932] 0.8246031517068708\n",
            "mae_cleanliness [0.7665987254933108, 0.7615676777412173, 0.7526866445132392, 0.7365002466184655, 0.7837204682615739] 0.7602147525255614\n",
            "mae_loc [0.6442101388177961, 0.6424114256733091, 0.625513414908339, 0.6463652083482269, 0.6319033495125962] 0.6380807074520535\n",
            "mae_rooms [0.8689010656187979, 0.8606580564362766, 0.8872985003016118, 0.8706293546168894, 0.8624858569371134] 0.8699945667821378\n",
            "mae_srv [0.8832320145569756, 0.8662905351823716, 0.9002263657726345, 0.8773861515418138, 0.9089110590112717] 0.8872092252130134\n",
            "mae_value [0.9770248460735528, 0.93959080067856, 0.9746598973763595, 0.9623411452045626, 0.9839658434749139] 0.9675165065615896\n",
            "rmse_hist [1.1292571438017642, 1.1104464243017358, 1.1288463747214934, 1.1065956690507595, 1.1290257450674697] 1.1208342713886443\n",
            "rmse_cleanliness [1.0713165833919485, 1.0739141036645958, 1.0563488911608252, 1.0357094280293488, 1.0870245443301276] 1.0648627101153694\n",
            "rmse_loc [0.930729994489736, 0.922595980166287, 0.9065296857846633, 0.9219108800052059, 0.9318329251957913] 0.9227198931283367\n",
            "rmse_rooms [1.152085952319969, 1.136379710333402, 1.177057052506124, 1.1503873115383305, 1.1350046895662929] 1.1501829432528237\n",
            "rmse_srv [1.2203786787630786, 1.1972452520925239, 1.2397744911424915, 1.1772660942821882, 1.2358653053027857] 1.2141059643166137\n",
            "rmse_value [1.2717745100440887, 1.2220970752518714, 1.2645217530133614, 1.2477046313987223, 1.2554012609423484] 1.2522998461300785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-WO-DNTmJI86"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}